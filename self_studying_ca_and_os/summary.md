# Chapter 01 컴퓨터 구조 시작하기
## 01-1 컴퓨터 구조를 알아야 하는 이유
* 문법만으로는 알기 어려운 성능/용량/비용을 고려하여 개발할 수 있다.

## 01-2 컴퓨터 구조의 큰 그림
### 컴퓨터 구조
* 컴퓨터 구조
	* 컴퓨터가 이해하는 정보
		* `데이터`
		* `명령어`
	* 컴퓨터의 4가지 핵심 부품
		* `CPU (중앙처리장치)`
		* `메모리 (주기억장치)`
			* RAM (Random Access Memory)
				특별한 언급이 없는 한 주기억장치 = RAM으로 생각
			* ROM (Read Only Memory)
		* `보조기억장치`
		* `입출력장치`
### 컴퓨터의 4가지 핵심 부품
* 컴퓨터의 핵심 부품 (구조)
	* 메인보드
		* `CPU`
			* ALU
			* 레지스터
			* 제어장치
		* `메모리`
		* 시스템 버스
	* `보조기억장치`
	* `입출력장치`
#### 메모리
* `현재 실행되는 프로그램의 명령어와 데이터를 저장`하는 부품
* 프로그램이 실행되려면 반드시 메모리에 저장되어 있어야 한다.
	* 현재 실행되는 프로그램의 명령어와 데이터를 저장한다.
* 메모리에 저장된 값에 빠르고 효율적으로 접근하기 위해 `주소 (address)`라는 개념이 사용된다.
#### CPU
* `메모리에 저장된 명령어를 읽어 들이고, 해석, 실행`하는 부품
* CPU 내부 구성요소
	* `ALU (산술논리연산장치)`
		* 계산기 역할
	* `레지스터`
		* 임시 저장 장치
		* 프로그램을 실행하는 데 필요한 값들을 임시로 저장
	* `제어장치`
		* `제어 신호 (control signal)`라는 전기 신호를 내보내고 명령어를 해석
		* CPU가 메모리에 저장된 값을 읽고 싶을 땐 메모리를 향해 `메모리 읽기`라는 제어 신호를 보낸다.
		* CPU가 메모리에 어떤 값을 저장하고 싶을 떈 메모리를 향해 `메모리 쓰기`라는 제어 신호를 보낸다.
    1. 제어장치가  메모리 읽기 제어 신호를 보내 명령어를 레지스터에 저장한 뒤 해석한다.
    2. 연산 결과를 메모리에 저장하라는 명령어가 해석되었을 때는 메모리 쓰기 제어 신호를 보내 값을 메모리에 저장한다.
#### 보조기억장치
* 전원이 꺼져도 저장된 내용을 잃지 않는 메모리를 보조하는 저장 장치
* 하드 디스크, SSD, USB 메모리, DVD 등
* 전원이 꺼져도 보관될 프로그램을 저장

#### 입출력장치
* 컴퓨터 외부에 연결되어 컴퓨터 내부와 정보를 교환하는 장치
* 마이크, 스피커, 프린터, 마우스, 키보드 등
* 보조기억장치도 관점에 따라 입출력장의 일종으로 볼 수 있음
	* `주변장치 (peripheral device)`라 통칭하기도 한다.
#### 메인보드와 시스템 버스
* `마더보드`라고도 부른다.
* 여러 컴퓨터 부품을 부착할 수 있는 슬롯과 연결 단자가 있다.
* 부품들은 메인보드 내의 `버스`라는 통로를 통해 서로 정보를 주고 받는다.
* 네 가지 핵심 부품을 연결하는 가장 중요한 버스는 `시스템 버스`이다.
	* 시스템 버스 (내부 구성)
		* `주소 버스`
			* 주소를 주고받는 통로
		* `데이터 버스`
			* 명령어와 데이터를 주고받는 통로
		* `제어 버스`
			* 제어 신호를 주고받는 통로
	* 메모리 1번지의 값을 읽기 위해서는
		1. `제어 버스`로 `메모리 읽기` 제어 신호를 보낸다.
		2. `주소 버스`로 읽고자 하는 `주소`를 보낸다.
		3. 그럼 메모리는 `데이터 버스`로 CPU가 요청한 주소에 있는 내용을 보낸다.
			또한 CPU가 메모리에 값을 저장할 때도 `데이터 버스`를 통해 저장할 값을 보낸다.
# Chapter 02 데이터
## 02-1 0과 1을 숫자로 표현하는 방법
### 정보 단위
* 0과 1을 나타내는 가장 작은 정보 단위를 `비트`라고 한다.
    *  n비트는 2<sup>n</sup>가지 정보를 표현할 수 있다.
* `바이트`는 8개의 비트를 묶은 단위이다.
    * 1바이트 = 8비트 = 2<sup>8</sup> = 256개의 정보를 표현 가능
* byte -> kB -> MB -> GB -> TB
    * 이전 단위를 1000개씩 묶어 표현
    * 1024개씩 묶은 건 KiB, MiB, GiB, TiB이다.
* `워드`란 CPU가 한 번에 처리할 수 있는 데이터 크기를 의미한다.
    * CPU가 한 번에 32비트를 처리할 수 있다면, 1워드 = 32비트
    * `하프 워드`, `풀 워드`, `더블 워드`
### 이진법
* 1을 넘어가는 시점에 자리 올림을 하여 0과 1만으로 모든 수를 표현하는 방법
#### 이진수의 음수 표현
* 가장 널리 사용되는 방법은 `2의 보수 (two's complement)`를 구해 음수로 간주하는 방법이다.
* 사전적 의미는 `어떤 수를 그보다 큰 2^n에서 뺀 값`을 의미한다.
	* 예를 들어 11<sub>(2)</sub>의 2의 보수는 11<sub>(2)</sub>보다 큰 2<sup>n</sup>, 즉 100<sub>(2)</sub>에서 11<sub>(2)</sub>를 뺀 01<sub>(2)</sub>이 되는 것이다.
* 쉽게 설명하자면 `모든 0과 1을 뒤집고, 거기에 1을 더한 값`으로 이해하면 된다.
	* 다만 n비트로는 -2<sup>n</sup>과 2<sup>n</sup>이라는 수를 동시에 표현할 수 없다.
* 컴퓨터 내부에서 어떤 수가 음수인지 양수인지를 구분하기 위해 `플래그`를 사용한다.
### 십육진법
* 데이터를 표현할 때 이진법을 사용하면 너무 길어지므로, 십육진법으로 나타낸다.
* 십육진수 15는 `15(16)` (수학적 표기 방식) 또는 `0x15` (코드상 표기 방식)으로 나타낸다.
#### 십육진수를 이진수로 변환하기
* 십육진수 숫자 하나가 4비트에 대응되므로, 4자리 이진수 숫자로 변환하면 된다.
## 02-2 0과 1로 문자를 표현하는 방법
### 문자 집합과 인코딩
* 컴퓨터가 인식하고 표현할 수 있는 문자의 모음을 `문자 집합 (character set)`이라고 한다.
* `문자 인코딩`을 통해 문자를 0과 1로 변환하여 컴퓨터가 이해할 수 있도록 한다.
* 반대의 과정은 `문자 디코딩`이라고 한다.
### 아스키 코드
* `아스키 (ASCII: American Standard Code for Information Interchange)`는 초창기 `문자 집합` 중 하나
* 아스키 문자 집합에 속한 문자 (이하 `아스키 문자`)들은 각각 7비트로 표현되는데, 따라서 128개의 문자를 표현할 수 있다.
	* 실제로는 하나의 아스키 문자를 나타내기 위해 8비트를 사용하지만, 8비트 중 1비트는 `패리티 비트`라고 불리는 오류 검출용 비트로 사용된다.
	* ex) 'A'는 십진수 65로 인코딩 된다.
		* 65와 같이 문자에 부여된 고유한 값을 `코드 포인트`라고 한다.
* 아스키 문자 집합에는 127개의 문자들만이 속해 있으므로, 모든 문자들을 표현하기에는 턱없이 모자라다.
	* 1비트를 추가해 8비트로 256개의 문자를 나타내는 `확장 아스키`가 등장하기도 했지만, 여전히 모자라다.
* 따라서 한국을 포함한 영어권 외의 나라들은 자신들의 언어를 0과 1로 표현할 수 있는 고유한 문자 집합과 인코딩 방식이 필요하다고 생각했다.
### EUC-KR
* 한글 인코딩에는 2가지 방식이 존재한다.
	* `완성형 인코딩`
		* 초성, 중성, 종성의 조합으로 이뤄진 완성된 하나의 글자에 고유한 코드를 부여한다.
		* 예를 들어 '가'는 1, '나'는 2, 이런식으로 인코딩하는 방식.
	* `조합형 인코딩`
		* 초성, 중성, 종성을 위한 비트열을 각각 할당하여 그것의 조합으로 하나의 글자 코드를 완성하는 방식.
* EUC-KR은 완성된 한글 단어에 2바이트 크기의 코드를 부여하는 `완성형 인코딩` 방식이다.
* 하지만 역시 모든 문자를 문자 집합 내에 정의하지 못한다.
	* 이를 개선하기 위해 `CP949 (code page 949)`가 등장했지만, 이마저도 넉넉한 양은 아니었음.
### 유니코드와 UTF-8
* EUC-KR 같은 인코딩 방식은 한글을 전부 표한하기에도 모자라고, 더욱이 언어별로 각기 다른 인코딩 방식을 사용할 수밖에 없었다.
* 그래서 등장한 것이 `유니코드` 문자 집합이다.
* 유니코드 문자 집합에서는 `아스키 코드`와 `EUC-KR`과 같이 각 문자마다 고유한 값이 부여된다. 예를 들어 '한'에 부여된 값은 D55C<sub>(16)</sub>이다.
* 유니코드는 이 값을 그대로 인코딩 값으로 삼지 않는다.
	* UTF-8, UTF-16, UTF-32 등 여러 방식을 이용해 문자에 부여된 값을 인코딩한다.
	* `UTF (unicode transformation format)`
	* `코드 포인트`의 범위에 따라 1, 2, 3, 4바이트로 변환된다.
	  * 이렇게 하는 이유는, 호환성과 효율성 때문이다.
	  * 예를 들어, 7비트 이하의 범위의 코드 포인트를 가져 1바이트로 변환되는 문자들은 ASCII 방식을 이용했을 때 동일하게 변환된다.
	  * '한' 의 경우는 3바이트로 변환된다.
	* `UTF-16`의 경우에는 대부분의 문자를 2바이트로 표시한다. 
		* UTF-8과 마찬가지로 `가변 길이 인코딩`이지만, 대부분의 문자를 2바이트로 표시한다.
		* 기본적으로 2바이트의 순서가 정해진 것이 아니기 때문에, 시스템에 따라 `BOM (byte order mark)`를 파일의 맨 앞에 삽입하여  `엔디언`이 올바르게 판단될 수 있도록 하기도 한다.
	* `UTF-32`는 `고정 길이 인코딩`이다. 하지만 낭비되는 용량이 크기 때문에 인터넷에서의 정보 교환용으로는 사실상 전혀 이용되지 않는다.
	  * 하지만 가변 길이 부호화를 고려할 필요가 없어 처리가 간단하다는 장점이 있어 프로그램 내부적으로는 자주 사용된다.
# Chapter 03 데이터
## 03-1 소스 코드와 명령어
* 모든 소스 코드는 컴퓨터 내부에서 명령어로 변환된다.
### 고급 언어와 저급 언어
* `고급 언어 (high-level programming language)`
	* 사람을 위한 언어 
	
* `저급 언어 (low-level programming language)`
	* 컴퓨터가 직접 이해하고 실행할 수 있는 언어
* 고급 언어로 작성된 소스 코드가 실행되려면 반드시 저급 언어, 즉 `명령어`로 변환되어야 한다.
* `저급 언어`
	* `기계어`
		* 0과 1의 명령어 비트로 이루어진 언어.
		* 즉 0과 1로 이루어진 명령어 모음이다.
		* 가독성을 위해 십육진수로 표현하기도 한다.
	* `어셈블리어`
		* 사람이 기계어를 직접 읽고 이해하기 어렵기 때문에, 기계어를 ㅇ릭기 편한 형태로 번역한 언어가 `어셈블리어`이다.
### 컴파일 언어와 인터프리터 언어
* 고급 언어를 저급 언어로 변환하는 방식은 크게 2가지, `컴파일` 방식과 `인터프리트` 방식이 있다.
#### 컴파일 언어
* 컴파일러에 의해 소스 코드 전체가 저급 언어로 변환되어 실행되는 고급 언어.
* 대표적으로 C가 있다.
* `컴파일`을 수행해주는 도구를 `컴파일러`라고 한다.
* 컴파일러를 통해 저급 언어로 변환된 코드를 `목적 코드(object code)`라고 한다.

#### 인터프리터 언어
* 인터프리터 언어는 `인터프리터`에 의해 소스 코드가 한 줄씩 실행되는 고급 언어이다.
* 대표적으로 Python이 있다.
* 소스 코드 전체를 저급 언어로 변환하는 시간을 기다릴 필요가 없다.
* 따라서 소스 코드 N번째 줄에 문법 오류가 있더라도 N - 1번째 줄까지는 올바르게 수행된다.
### 목적 파일 VS 실행 파일
* `목적 코드`로 이루어진 파일을 `목적 파일`이라고 한다.
* 마찬가지로 `실행 코드`로 이루어진 파일을 `실행 파일`이라고 한다.
* 목적코드가 실행 파일이 되기 위해서는 `링킹`이라는 작업을 거쳐야 한다.
	* main.c와 helper.c를 각각 main.o, helper.o로 `컴파일`한다.
	* main.o에서 'HELPER 더하기' 를 수행하기 위해서는 main.o에 없는 외부 기능을 연결 짓는 작업이 필요하다. 이러한 연결 작업이 `링킹`이다.
	* 링킹 작업까지 거치면 비로소 하나의 `실행 파일`이 만들어진다.
## 03-2 명령어의 구조
* `연산 코드`, `오퍼랜드`, `주소 지정 방식`
### 연산 코드와 오퍼랜드
* 명령어는 '명령어가 수행할 연산'인 `연산 코드 (연산자)`와 '연산에 사용할 데이터'인 `오퍼랜드 (피연산자)`로 이루어져 있다.
* 연산 코드가 담기는 영역을 `연산 코드 필드`, 오퍼랜드가 담기는 영역을 `오퍼랜드 필드`라고 한다.
### 오퍼랜드
* 오퍼랜드 필드에는 숫자와 문자 등을 나타내는 데이터 또는 메모리나 레지스터 주소가 올 수 있다.
* 많은 경우에는 연산에 사용할 데이터가 저장된 `위치`, 즉 `메모리 주소`나 `레지스터 이름`이 담긴다.
* 따라서 오퍼랜드 필드를 `주소 필드`라고 부르기도 한다.
	* mov eax, 0 -> 오퍼랜드가 2개인 경우
	* pop rbg -> 오퍼랜드가 1개인 경우
	* ret -> 오퍼랜드가 없는 경우
* 오퍼랜드의 개수에 따라 명령어를 `0-주소`, `1-주소`, `2-주소`, `3-주소 명령어`라고 한다.
### 연산 코드
* 연산 코드 유형은 크게 4가지로 나눌 수 있다.
	* `데이터 전송`
		* MOVE: 데이터를 옮겨라
		* STORE: 메모리에 저장하라
		* LOAD (FETCH): 메모리에서 CPU로 데이터를 가져와라
		* PUSH: 스택에 데이터를 저장하라
		* POP: 스택의 최상단 데이터를 가져와라
	* `산술/논리 연산`
		* ADD / SUBTRACT / MULTIPLY / DIVIDE
		* INCREMENT / DECREMENT: 오퍼랜드에 1을 더하라 / 빼라
		* AND  / OR / NOT
		* COMPARE: 2개의 숫자 또는 TRUE / FALSE 값을 비교하라
	* `제어 흐름 변경`
		* JUMP: 특정 주소로 실행 순서를 옮겨라
		* CONDITIONAL JUMP: 조건에 부합할 때 특정 주소로 JUMP
		* HALT: 프로그램의 실행을 멈춰라
		* CALL: 되돌아올 주소를 저장한 채 특정 주소로 실행 순서를 옮겨라
		* RETURN: CALL을 호출할 때 저장했던 주소로 돌아가라
	* `입출력 제어`
		* READ (INPUT): 특정 입출력 장치로부터 데이터를 읽어라
		* WRITE (OUTPUT): 특정 이불력 장치로 데이터를 써라
		* START IO: 입출력 장치를 시작하라
		* TEST IO: 입출력 장치의 상태를 확인하라
### 주소 지정 방식
* 오퍼랜드 필드에 메모리나 레지스터의 `주소`를 담는 이유가 무엇일까?
	* 데이터를 직접 담게 되면 오퍼랜드 필드에 할당된 비트만큼의 가짓수만 표현할 수 있지만, 주소를 담게 되면 주소에 저장할 수 있는 공간의 크기만큼 데이터를 표현할 수 있다.
* 연산 코드에 사용할 데이터가 저장된 위치, 즉 연산의 대상이 되는 데이터가 저장된 위치를 `유효 주소`라고 한다.
* 오퍼랜드 필드에 데이터가 저장된 위치를 명시할 때 연산에 사용할 데이터 위치를 찾는 방법을 `주소 지정 방식 (addressing mode)`라고 한다.
* 즉, 주소 지정 방식은 `유효 주소`를 찾는 방법이다.
#### 즉시 주소 지정 방식
* `즉시 주소 지정 방식 (immediate addressing mode)`은 연산에 사용할 `데이터`를 오퍼랜드 필드에 직접 명시하는 방식이다.
* 표현할 수 있는 데이터의 크기가 작지만, 가장 빠르다.
#### 직접 주소 지정 방식
* `직접 주소 지벙 방식 (direct addressing mode)`은 오퍼랜드 필드에 `유효 주소`를 직접 명시하는 방식이다.
* 하지만 여전히 유효 주소를 표현할 수 있는 범위가 오퍼랜드 필드의 비트 수만큼으로 줄어든다.
#### 간접 주소 지정 방식
* `간접 주소 지정 방식 (indirect addressing mode)`은 `유효 주소의 주소`를 오퍼랜드 필드에 명시한다.
* 하지만 2번의 메모리 접근이 필요하기 때문에 앞선 방식들보다 느리다.
#### 레지스터 주소 지정 방식
* `레지스터 주소 지정 방식 (register addressing mode)`은 연산에 사용할 데이터를 저장한 `레지스터`를 오퍼랜드 필드에 직접 명시하는 방법이다.
* CPU 외부에 있는 메모리에 접근하는 것보다 CPU 내부의 레지스터에 접근하는 것이 더 빠르다.
* 하지만 표현할 수 있는 레지스터 크기에 제한이 생길 수 있다.
#### 레지스터 간접 주소 지정 방식
* `레지스터 간접 주소 지정 방식 (register indirect addressing mode)`은 사용할 `데이터를 메모리에 저장`하고, `해당 유효 주소를 저장한 레지스터`를 오퍼랜드 필드에 명시하는 방법이다.
* `간접 주소 지정 방식`과 비슷하지만, `메모리 접근`이 `1번`만 이뤄지므로 더 빠르다.
# Chapter 04 CPU의 작동 원리
## 04-1 ALU와 제어장치
* CPU는 메모리에 저장된 명령어를 읽어 들이고, 해석하고, 실행하는 장치
* CPU 내부에는 계산을 담당하는 `ALU`, 명령어를 읽어 들이고 해석하는 `제어장치`, 작은 임시 저장 장치인 `레지스터`라는 구성 요소가 있다.

### ALU
* `ALU (arithmetic-logic unit)`
* ALU는 레지스터를 통해 `피연산자`를 받아들이고, 제어장치로부터 수행할 연산을 알려주는 `제어 신호`를 받아들인다. ALU는 산술 연산, 논리 연산 등 다양한 `연산을 수행`한다.
* 연산을 수행한 결과는 `특정 숫자나 문자`가 될 수도 있고, `메모리 주소`가 될 수도 있다. 이 결과값은 메모리에 바로 저장되지 않고 `일시적으로 레지스터에 저장`된다.
	* ALU가 연산을 할 때마다 결과값을 메모리에 저장한다면 CPU가 메모리에 자주 접근해야 하고, 따라서 CPU가 프로그램 실행 속도를 늦출 것이다.
* 계산 결과와 더불어 `플래그`를 내보낸다.
	* 가령 연산 결과가 음수일 때는 `방금 게산한 결과는 음수`라는 추가 정보를 내보낸다.
	* 혹은 연산 결과가 연산 결과를 담을 레지스터보다 클 때 `결과값이 너무 크다`라는 추가 정보를 내보낸다.
* 이러한 연산 결과에 대한 추가적인 상태 정보를 `플래그`라고 한다. ALU가 내보내는 대표적인 플래그는 다음과 같다.
	* `부호 플래그`: 연산한 결과의 부호 (1이면 음수, 0이면 양수)
	* `제로 플래그`: 연산 결과가 0인지 여부 (1이면 0, 0이면 0이 아님)
	* `캐리 플래그`: 연산 결과 올림수나 빌림수가 발생했는 지 (1일 경우 발생, 0일 경우 발생 X)
	* `오버플로우 플래그`: (1인 경우 오버플로우 발생, 0인 경우 발생 X)
	* `인터럽트 플래그`: (1인 경우 인터럽트 가능, 0인 경우 불가능)
	* `슈퍼바이저 플래그`: (1인 경우 커널 모드로 실행, 0인 경우 사용자 모드로 실행 중)
* 플래그들은 `플래그 레지스터`에 저장된다. 플래그 레지스터에 `플래그 비트`들이 모여있다.
* ALU 내부에는 여러 계산들을 위한 회로가 있다.
	* `가산기`, `보수기`, `시프터`, `오버플로우 검출기` 등 -> 이 책에서는 회로를 다루지 않으므로 자세한 내용은 생략
### 제어장치
* `제어장치`는 제어 신호를 내보내고, 명령어를 해석하는 부품
* `제어 신호`는 컴퓨터 부품을 관리하고 작동시키기 위한 일종의 `전기 신호`
* 가장 정교하게 설게된 부품이라고 해도 과언이 아니다. 따라서 CPU 제조사마다 제어장치의 구현 방식이나 명령어 해석 방식, 받아들이고 내보내는 정보에는 조금씩 차이가 있다.
#### 첫째, 제어장치는 클럭 신호를 받아들인다.
* `클럭 (clock)`이란 컴퓨터의 모든 부품을 움직일 수 있게 하는 시간 단위이다.
* 하나의 명령어가 여러 클럭에 걸쳐 실행될 수 있다.
#### 둘째,  '해석해야 할 명령어'를 받아들인다.
* `명령어 레지스터`로부터 해석할 `명령어`를 받아들이고 해석한 뒤, 제어 신호를 발생시킨다.
#### 셋째, 플래그 레지스터 속 플래그 값을 받아들인다.
* `플레그 레지스터`로부터 `플래그` 값을 받아들이고 참고하여 제어 신호를 발생시킨다.
#### 넷째, 시스템 버스, 그중에서 제어 버스로 전달된 제어 신호를 받아들인다.
* `제어 신호`는 CPU 뿐만이 아니라 CPU 외부 장치도 발생시킬 수 있다.
* 제어 장치는 `제어 버스`를 통해 외부로부터 전달된 제어 신호를 받아들이기도 한다.
#### 제어장치가 내보내는 정보
* `메모리`에 저장된 값을 읽거나 쓰고 싶다면 메모리로 `제어 신호`를 내보낸다.
* `입출력장치`에 저장된 값을 읽거나 쓰고 싶다면 입출력장치로 제어 신호를 내보낸다.
* CPU 내부에 전달하는 제어 신호는 크게 `ALU`에 전달하는 제어 신호와 `레지스터`에 전달하는 제어 신호가 있다. ALU에는 `수행하는 연산을 지시`하기 위해, 레지스터에는 `레지스터 간에 데이터를 이동`시키거나 `레지스터에 저장된 명령어를 해석`하기 위해 제어 신호를 내보낸다.
## 04-2 레지스터
* `프로그램` 속 `명령어`와 `데이터`는 실행 전후로 반드시 `레지스터`에 저장된다.
* 따라서 레지스터만 잘 관찰해도 프로그램의 자세한 실행 과정을 알 수 있다.
### 반드시 알아야 할 레지스터
* 상용화된 CPU 속 레지스터들은 CPU마다 이름, 크기, 종류가 매우 다양하다.
* 많은 CPU가 공통으로 포함하는 `8개`의 레지스터에 대해 알아보자.
	* `프로그램 카운터`
	* `명령어 레지스터`
	* `메모리 주소 레지스터`
	* `메모리 버퍼 레지스터`
	* `플래그 레지스터`
	* `범용 레지스터`
	* `스택 레지스터`
	* `베이스 레지스터`
#### 프로그램 카운터
* `프로그램 카운터 (PC: program counter)`는 메모리에서 가져올 명령어의 주소, 즉 `메모리에서 읽어 들일 명령어의 주소`를 저장한다. `명령어 포인터`라고 부르는 CPU도 있다.
#### 명령어 레지스터
* `명령어 레지스터 (IR: instruction register)`는 해석할 명령어, 즉 `방금 메모리에서 읽어들인 명령어`를 저장하는 레지스터이다. 제어장치는 명령어 레지스터 속 명령어를 받아들이고 이를 해석한 뒤 제어 신호를 내보낸다.
#### 메모리 주소 레지스터
* `메모리 주소 레지스터 (MAR: memory address register)`는 `메모리의 주소`를 저장하는 레지스터이다. CPU가 읽어 들이고자 하는 주소 값을 `주소 버스`로 보낼 때 메모리 주소 레지스터를 거치게 된다.
#### 메모리 버퍼 레지스터
* `메모리 버퍼 레지스터 (MBR: memory buffet register)`는 `메모리와 주고받을 값(데이터와 명령어)`를 저장하는 레지스터이다. 즉, CPU가 주소 버스로 주고 받을 값은 MAR을, `데이터 버스`로 주고 받을 값은 MBR을 거친다. MBR은 `메모리 데이터 레지스터 (MDR)`라고도 부른다.
##### 메모리에 저장된 프로그램을 실행하는 과정에서 각 레지스터에 어떤 값들이 담기는지 알아보자
```
1. CPU로 실행할 프로그램이 `1000`번지부터 `1500`번지까지 저장되어 있다고 가정해보자. 그리고 1000번지에는 `1101₂`이 저장되어 있다고 가정해보자. (각 명령어가 하나의 번지를 차지하고 있다고 가정)
2. 프로그램을 처음부터 실행하기 위해 `프로그램 카운터`에는 `1000`이 저장된다. 이는 메모리에서 가져올 명령어가 1000번지에 있다는 걸 의미한다.
3. 1000번지를 읽어 들이기 위해 `주소 버스`로 1000번지를 내보내야 한다. 이를 위해 `메모리 주소 레지스터`에 1000이 저장된다.
4. `메모리 읽기`제어 신호와 `메모리 주소 레지스터 값`이 각각 `제어 버스`와 `주소 버스`를 통해 메모리로 보내진다.
5. 메모리 1000번지에 저장된 값은 `데이터 버스`를 통해 `메모리 버퍼 레지스터`로 전달되고, `프로그램 카운터`는 증가되어 다음 명령어를 읽어 들일 준비를 한다.
6. `메모리 버퍼 레지스터`에 저장된 값은 `명령어 레지스터`로 이동한다.
7. `제어 장치`는 `명령어 레지스터`의 `명령어`를 해석하고 `제어 신호`를 발생시킨다.
```
#### 범용 레지스터
* `범용 레지스터(general purpose register)`는 다양하고 일반적인 상황에서 자유롭게 사용할 수 있다. `데이터`와 `주소`를 모두 저장할 수 있다. 일반적으로 CPU 안에는 여러 개의 범용 레지스터들이 있다.
#### 플래그 레지스터
* `플래그 레지스터`는 ALU 연산 결과에 따른 `플래그`또는 CPU 상태에 대한 부가적인 정보를 저장한다.
### 특정 레지스터를 이용한 주소 지정 방식(1): 스택 주소 지정 방식
* `프로그램 카운터`, `베이스 레지스터`, `스택 포인터`는 주소 지정에 사용될 수 있는 특별한 레지스터이다.
* `스택 포인터`는 `스택 주소 지정 방식`에 사용되고, `프로그램 카운터`와 `베이스 레지스터`는 `변위 주소 지정 방식`에 사용된다.
* `스택 주소 지정 방식`은 `스택`과 `스택 포인터`를 이용한 주소 지정 방식이다. `스택 포인터`란 스택의 꼭대기를 가리키는 레지스터이다. 즉 스택 포인터는 `스택에 마지막으로 저장된 값의 위치`를 저장하는 레지스터이다.
* `메모리`안에는 스택처럼 사용할 영역인 `스택 영역`이 존재한다. 이 영역은 다른 주소 공간과는 다르게 스택처럼 사용하기로 암묵적으로 약속된 영역이다.
### 특정 레지스터를 이용한 주소 지정 방식(2): 변위 주소 지정 방식
* 03장에서 `명령어`는 `연산 코드`와 `오퍼랜드`로 이루어져 있다고 언급한 적이 있다. 그리고 `오퍼랜드 필드`에는 `주소`가 담길 때도 있다고 했다.
* `변위 주소 지정 방식 (displacement addressing mode)`란 `오퍼랜드 필드의 값(변위)`와 `특정 레지스터의 값`을 더하여 `유효 주소`를 얻어내는 주소 지정 방식이다.
* 따라서 변위 주소 지정 방식을 사용하는 명령어는 `연산 코드 필드`, `레지스터 필드`, 주소를 담고 있는 `오퍼랜드 필드`로 이뤄져 있다.  (레지스터 값 + 주소를 더한 곳에 있는 데이터롤 연산을 수행)
	* 이때, 오퍼랜드 필드의 주소와 어떤 레지스터를 더하는지에 따라 `상대 주소 지정 방식`, `베이스 레지스터 주소 지정 방식`으로 나뉜다.
#### 상대 주소 지정 방식
* `상대 주소 지정 방식 (relative addressing mode)`은 `오퍼랜드`와 `프로그램 카운터`의 값을 더하여 `유효 주소`를 얻는 방식이다.
	* 명령어가 (연산코드 / 프로그램 카운터 / -3)인 경우 CPU는 읽어 들이기로 한 명령어로부터 `세 번째 이전` 번지로 접근하여 해당 명령어를 실행한다.
* 프로그래밍 언어의 `if`문과 유사하게 모든 코드를 실행하는 것이 아닌, `분기`하여 특정 주소의 코드를 실행할 때 사용된다.
#### 베이스 레지스터 주소 지정 방식
* `베이스 레지스터 주소 지정 방식 (base-register addressing mode)`은 `오퍼랜드`와 `베이스 레지스터`의 값을 더하여 `유효 주소`를 얻는 방식이다.
* 베이스 레지스터는 `기준 주소`, 오퍼랜드는 `기준 주소로부터 떨어진 거리`로서의 역할을 한다.
#### 상용화된 CPU 속 레지스터에 관한 참고 자료
https://github.com/kangtegong/self-learning-cs/blob/main/registers/registers.md
## 04-3 명령어 사이클과 인터럽트
* CPU가 하나의 명령어를 처리하는 과정에는 어떤 정해진 `흐름`이 있고, CPU는 그 흐름을 `반복`하여 명령어들을 처리해 나간다. 이렇게 하나의 명령어를 처리하는 정형화된 흐름을 `명령어 사이클`이라고 한다.
* CPU는 정해진 흐름에 따라 명령어를 처리해 나가지만, 간혹 이 `흐름이 끊어지는 상황`이 발생한다. 이를 `인터럽트`라고 한다.
### 명령어 사이클
* 프로그램은 수많은 명령어로 이루어져 있고, CPU는 이 명령어들을 하나씩 실행한다. 이때 프로그램 속의 각각의 명령어들은 일정한 주기가 반복되며 실행되는데, 이 주기를 `명령어 사이클 (instruction cycle)`이라고 한다.
* 메모리에 저장된 명령어 하나를 실행한다고 가정해 보자. 가장 먼저 명령어를 메모리에서 CPU로 가져와야 한다. 이것이 명령어 사이클의 첫 번째 과정인 `인출 사이클 (fetch cycle)`이다.
* CPU로부터 명령어를 인출했다면 이제 명령어를 실행한다. 이것이 명령어 사이클의 두 번째 과정인 `실행 사이클 (execution cycle)`이다. `제어장치`가 `명령어 레지스터`에 담긴 값을 해석하고, `제어 신호`를 발생시키는 단계이다.
* 프로그램을 이루는 수많은 명령어는 일반적으로 `인출`과 `실행`사이클을 반복하며 실행한다.
* `간접 주소 지정 방식`의 경우 `유효 주소`를 얻기 위한 `간접 사이클 (indirect cycle)` 단계를 수행해야 한다.
### 인터럽트
* CPU가 수행 중인 작업은 방해를 받아 잠시 중단될 수 있는데, 이렇게 CPU의 작업을 방해하는 `신호`를 `인터럽트`라고 한다.
* 인터럽트의 종류에는 크게 `동기 인터럽트`와 `비동기 인터럽트`가 있다.
* `동기 인터럽트 (synchronous interrupts)`
	* `CPU`에 의해 발생하는 인터럽트이다.
	* CPU가 명령어들을 수행하다가, 프로그래밍상의 오류와 같은 예상치 못한 상황에 마주쳤을 때 발생하는 인터럽트이다.
		* 이런 접에서 `예외 (exception)`라고 부른다.
* `비동기 인터럽트 (asynchronous interrupts)`
	* 주로 `입출력장치`에 의해 발생하는 인터럽트이다.
		* CPU가 프린터와 같은 입출력장치에 I/O 작업을 부탁하면 작업을 끝낸 입출력장치가 CPU에 `완료 알림(인터럽트)`를 보낸다.
		* 키보드, 마우스가 `입력 알림(인터럽트)`를 보낸다.
	* 일반적으로 비동기 인터럽트를 `인터럽트`라고 칭하기도 하지만, 용어의 혼동을 방지하기 위해 `하드웨어 인터럽트`라는 용어를 사용하자.
#### 하드웨어 인터럽트
* `하드웨어 인터럽트`는 `알림`과 같은 인터럽트이다.
* CPU는 입출력 작업 도중에도 효율적으로 명령어를 처리하기 위해 이런 알림과 같은 하드웨어 인터럽트를 사용한다.
	* 예를 들어, CPU가 프린터에 출력을 명령했다고 가정해 보자.
	* CPU는 프린터의 작업이 끝나기를 기다릴 필요 없이 인터럽트를 받을 때까지 다른 작업을 수처리할 수 있다.
#### 하드웨어 인터럽트 처리 순서
```
1. 입출력장치는 CPU에 `인터럽트 요청 신호`를 보낸다.
2. CPU는 `실행 사이클`이 끝나고 `명령어를 인출`하기 전 항상 `인터럽트 여부`를 확인한다.
3. CPU는 `인터럽트 요청`을 확인하고 `인터럽트 플래그`를 통해 현재 인터럽트를 받아들일 수 있는 `여부를 확인`한다.
4. 인터럽트를 받아들일 수 있다면 CPU는 지금까지의 작업을 `백업`한다.
5. CPU는 `인터럽트 벡터`를 참조하여 `인터럽트 서비스 루틴`을 실행한다.
6. 인터럽트 서비스 루틴 실행이 끝나면 백업해 둔 작업을 `복구`하여 `실행을 재개`한다.
```
* `인터럽트 요청 신호`
	* 다른 누군가가 인터럽트하기 전에는 지금 끼어들어도 되는지에 대한 여부를 CPU에 물어봐야 한다. 이를 `인터럽트 요청 신호`라고 한다.
* `인터럽트 플래그`
	* 이때, CPU가 인터럽트 요청을 수용하기 위해서는 `플래그 레지스터`의 `인터럽트 플래그`가 활성화되어 있어야 한다.
	* CPU가 중요한 작업을 처리해야 할 때 해당 플래그를 비활성화 해놓을 수도 있다. 이 경우 인터럽트 요청이 오더라도 해당 요청을 무시한다.
		* 모든 하드웨어 인터럽트를 `인터럽트 플래그`로 막을 수 있는 건 아니다.
		* `정전`이나 `하드웨어 고장`으로 인한 인터럽트는 반드시 가장 먼저 처리해야 한다.
* `인터럽트 서비스 루틴 (ISR: interrupt service routine)`
	* CPU가 인터럽트 요청을 받아들이기로 했다면, CPU는 `인터럽트 서비스 루틴`이라는 프로그램을 실행한다. `인터럽트 핸들러`라고도 부른다.
	* ISR은 어떤 인터럽트가 발생했을 때 해당 인터럽트를 어떻게 처리하고 작동해야 할지에 대한 정보로 이루어진 `프로그램`이다.
		* `프로그램`이므로 명령어와 데이터로 이루어져 있으며 PC와 같은 레지스터를 상용하며 실행된다.
		* 기존 작업 내역은 `스택`에 백업된다.

`CPU가 인터럽트를 처리한다`는 말은 `인터럽트 서비스 루틴을 실행하고, 본래 수행하던 작업으로 다시 되돌아온다`라는 말과 같다.
* `인터럽트 벡터 (interrupt vector)`
	* 인터럽트를 처리하는 방법은 입출력장치마다 다르므로, 각기 다른 `ISR`을 가지고 있다. 즉, `메모리`에는 여러 개의 ISR이 저장되어 있다.
	* 따라서 CPU는 각기 다른 ISR을 구분하기 위해 `인터럽트 벡터`를 이용한다.
	* 인터럽트 벡터는 `ISR을 식별하기 위한 정보`이다.
	* 인터럽트 벡터를 알면 `ISR의 시작 주소`를 알 수 있기 때문에, CPU는 인터럽트 벡터를 통해 특정 ISR를 처음부터 실행할 수 있다.
		* CPU는 하드웨어 인터럽트 요청을 보낸 대상으로부터 `데이터 버스`를 통해 `인터럽트 벡터`를 전달받는다.
	* 각 인터럽트 벡터에는 `번호`가 할당되어 있으며, `OS`는 `부팅`시 `인터럽트 벡터 테이블`에 대응되는 `ISR의 시작 주소`값을 할당한다.
#### 예외의 종류
* `예외`가 발생하면 CPU는 하던 일을 중단하고 해당 예외를 처리한다. 예외를 처리하고 나면 CPU는 다시 본래 하던 작업으로 되돌아와 실행을 재개한다. 이때 CPU가 `예외가 발생한 명령어`부터 실행하느냐, 예외가 발생한 명령어의 `다음 명령어`부터 실행하느냐에 따라 `폴트`와 `트랩`으로 나뉜다.
* `폴트 (fault)`는 예외를 처리한 직후 예외가 발생한 명령어부터 실행을 재개하는 예외이다.
	* 가령 CPU가 한 명령어를 실행하는데, 필요한 데이터가 메모리가 아닌 보조기억장치에 있다고 가정해보자. 프로그램이 실행되려면 반드시 메모리에 저장되어 있어야 하기에 CPU는 `폴트`를 발생시키고 데이터를 메모리로 가져와 저장한다.
	* CPU는 실행을 재개하고, 폴트가 발생한 그 명령어부터 실행한다.
* `트랩 (trap)`은 예외를 처리한 직후 예외가 발생한 명령어의 다음 명령어부터 실행을 재개하는 예외이다.
	* 주로 `디버깅`할 때 사용한다.
	* 디버깅을 할 때 특정 코드가 실행하는 순간 프로그램의 실행을 멈출 수 있다. 
	* 트랩을 처리하고 나면, 다시 말해 디버깅이 끝나면 프로그램은 다음 명령어부터 실행을 이어 나가면 된다.
* `중단 (abort)`은 CPU가 실행 중인 프로그램을 강제로 중단시킬 수밖에 없는 `심각한 오류`를 발생했을 떄 발생하는 예외이다.
* `소프트웨어 인터럽트`는 `시스템 호출`이 발생했을 때 나타난다.
# Chapter 05 CPU 성능 향상 기법
## 05-1 빠른 CPU를 위한 설계 기법
### 클럭
* `클럭 속도`가 높아지면 CPU는 `명령어 사이클`을 더 빠르게 반복할 것이고, 다른 부품들도 그에 발맞춰 더 빠르게 작동할 것이다.
* `클럭 속도`는 CPU 속도 단위로 간주되기도 한다.
* `클럭 속도`
	* 헤르츠 (Hz) 단위로 측정한다. 이는 `1초`에 클럭이 `몇 번` 반복되는지를 나타낸다.
	* 기본 속도(Base)가 2.5GHz, 최대 속도(Max)가 4.9Hz인 CPU의 경우 1초에 클럭이 기본적으로 25억번, 순간적으로 최대 49억번 반복된다는 것을 나타낸다.
		* 클럭 속도는 일정하지 않다.
### 코어와 멀티코어
* CPU의 `코어`와 `스레드` 수를 늘려 성능을 높일 수 있다.
* `코어`란 CPU 내에서 명령어를 실행하는 부품으로, 여러 개가 있을 수 있다.
* `코어`를 여러 개 포함하고 있는 CPU를 `멀티코어 CPU` 또는 `멀티코어 프로세서`라고 부른다.
* 다만 CPU의 연산 속도가 꼭 코어 수에 비례하여 증가하지는 않는다.
* 따라서 코어마다 처리할 연산을 적절히 분배해야 한다.
### 스레드와 멀티스레드
* `스레드`의 사전적 의미는 `실행 흐름의 단위`이다.
* 하지만 CPU에서 사용되는 스레드와 프로그래밍에서 사용되는 스레드는 용례가 다르다.
	* CPU에서 사용되는 스레드를 `하드웨어적 스레드`라고 한다.
	* 또한 프로그램에서 사용되는 `소프트웨어적 스레드`가 있다.
#### 하드웨어적 스레드
* `하나의 코어가 동시에 처리하는 명령어 단위`를 의미한다.
* 여러 `스레드`를 지원하는 CPU는 `하나의 코어`로도 `여러 개의 명령어`를 `동시에 실행`할 수 있다.
	* 예를 들어 `2코어 4스레드 CPU`는 명령어를 실행하는 부품을 2개 포함하고, 한 번에 4개의 명령어를 처리할 수 있는 CPU를 의미한다.
* 이처럼 하나의 코어로 여러 명령어를 동시에 처리하는 CPU를 `멀티스레드 프로세서` 또는 `멀티스레드 CPU`라고 한다.
* `하이퍼스레딩`은 인텔의 멀티스레드 기술을 의미한다.
#### 소프트웨어적 스레드
* `하나의 프로그램에서 독립적으로 실행되는 단위`를 의미한다.
* 하나의 프로그램은 실행되는 과정에서 한 부분만 실행될 수도 있지만(`싱글스레드`), 여러 부분이 동시에 실행될 수도 있다(`멀티스레드`).
#### 멀티스레드 프로세서
* 용어의 혼동을 방지하기 위해 이제부터 `소프트웨어`적으로 정의된 스레드는 `스레드`,  `CPU에서 사용되는` 스레드는 `하드웨어 스레드`라고 지칭하겠다.
* `멀티스레드 프로세서`는 `하나의 코어`로 `여러 명령어`를 `동시에 처리`하는 `CPU`이다. 어떻게 이런 일이 가능할까?
	* 실제로 설계하는 일은 매우 복잡하지만, 가장 큰 핵심은 `레지스터`이다.
	* 가령 `프로그램 카운터`가 2개 있다면, 메모리에서 가져올 명령어 주소를 2개 지정할 수 있을 것이다.
	* 이처럼 하나의 명령어를 실행하기 위해 꼭 필요한 레지스트들을 편의상 `레지스터 세트`라고 부르면, 레지스터 세트가 2개인 CPU는 2개의 명령어를 처리하기 위한 정보들을 기억할 수 있다. 여기서 `ALU`와 `제어장치`가 2개의 레지스터 세트에 저장된 명령어를 해석하고 실행하면, `하나의 코어에서 2개의 명령어가 동시에 실행`된다.
* 메모리 속 프로그램 입장에서 봤을 때, 하드웨어 스레드는 마치 `한 번에 하나의 명령어를 처리하는 CPU`와 다름없을 것이다. 따라서 하드웨어 스레드를 `논리 프로세서 (logical processor)`라고 부르기도 한다.
## 05-2 명령어 병렬 처리 기법
* 명령어를 동시에 처리하여 CPU를 쉬지 않고 작동시키는 기법인 `명령어 병렬 처리 기법 (ILP: insturction-level parallelism)`을 알아보자.
* 대표적인 `ILP`에는 `명령어 파이프라이닝`, `슈퍼스칼라`, `비순차적 명령어 처리`가 있다.
### 명령어 파이프라인
* 하나의 명령어 처리 과정을 클럭 단위로 나누어 보면 일반적으로 다음과 같이 나눌 수 있다.
	1. 명령어 인출 (Instruction Fetch)
	2. 명령어 해석 (Instruction Decode)
	3. 명령어 실행  (Execution Instruction)
	4. 결과 저장 (Write Back)
* 여기서 중요한 점은, 같은 단계가 겹치지만 않는다면 CPU는 `각 단계를 동시에 실행할 수 있다`는 것이다.
* 마치 공장 생산 라인과 같이 명령어들을 `명령어 파이프라인 (instruction pipeline)`에 넣고 동시에 처리하는 기법을 `명령어 파이프라이닝 (instruction pipelining)`이라고 한다.
* 파이프라이닝이 높은 성능을 가져오기는 하지만, 특정 상황에서는 성능 향상에 실패하기도 한다. 이러한 상황을 `파이프라인 위험 (pipeline hazard)`라고 부르며, 파이프라인 위험에는 크게 `데이터 위험`, `제어 위험`, `구조적 위험`이 있다.
#### 데이터 위험
* `데이터 위험 (data hazard)`은 명령어 간 `데이터 의존성`에 의해 발생한다. 어떤 명령어는 이전 명령어를 끝까지 실행해야만  비로소 실행할 수 있는 경우가 있다.
		명령어 1: R1 <- R2 + R3
		명령어 2: R4 <- R1 + R5
* 위의 경우 명령어 1을 수행해야만 명령어 2를 수행할 수 있다.
* 이처럼 데이터 의존적인 두 명령어를 무작정 동시에 실행하려고 하면 파이프라인이 제대로 작동하지 않는 것을 `데이터 위험`이라고 한다.
#### 제어 위험
* `제어 위험 (control hazard)`는 주로 분기 등으로 인한 `프로그램 카운터의 갑작스러운 변화`에 의해 발생한다.
* 만약 `프로그램 카운터`의 값에 변화가 생기면, `파이프라인`에 미리 가지고 와서 처리 중이었던 명령어들은 아무 쓸모가 없어진다. 이를 `제어 위험`이라고 한다.
* 이를 위해 사용하는 기술 중 하나가 `분기 예측 (branch prediction)`이다. 분기 예측은 프로그램이 어디로 분기할지 미리 예측한 후 그 주소를 인출하는 기술이다.
#### 구조적 위험
* `구조적 위험 (structural hazard)`은 명령어들을 겹쳐 실행하는 과정에서 서로 다른 명령어가 동시에 ALU, 레지스터 등과 같은 CPU 부품을 사용하려고 할 때 발생한다. `자원 위험 (resource hazard)`라고도 부른다.
### 슈퍼스칼라
* CPU 내부에 여러 개의 명령어 파이프라인을 포함한 구조를 `슈퍼스칼라 (superscalar)`라고 한다.
* 슈퍼스칼라 구조로 명령어 처리가 가능한 CPU를 `슈퍼스칼라 프로세서` 또는 `슈퍼스칼라 CPU`라고 한다. 슈퍼스칼라 프로세서는 매 클럭 주기마다 동시에 여려 명령어를 인출할 수도, 실행할 수도 있다. 
* 가령 `멀티스레드 프로세서`는 한 번에 여러 명령어를 인출, 해석, 실행할 수 있기 때문에 슈퍼스칼라 구조를 사용할 수 있다.
### 비순차적 명령어 처리
* `비순차적 명령어 처리 (OoOE: out-of-order execution)`
* 지금까지 설명했던 `명령어 파이프라이닝`, `슈퍼스칼라` 기법은 모두 명령어의 `순차적인 처리`를 상정한 방법이었다. 하지만 항상 명령어를 순차적으로만 처리한다면, `파이프라인 위험`과 같은 예상치 못한 상황에서 명령어 파이프라인은 멈춰버리게 된다.
* 순서를 바꿔 처리해도 수행 결과에 영향을 미치지 않는 명령어들을 먼저 처리함으로써 명령어 파이프라인이 멈추는 것을 방지하는 기법을 `비순차적 명령어 처리 기법`이라고 한다.
* 비순차적 명령어 처리가 가능한 CPU는 명령어들이 어떤 명령어와 `데이터 의존성`을 가지고 있는지, 순서를 바꿔 실행할 수 있는 명령어에는 어떤 것들이 있는지 판단할 수 있어야 한다.
## 05-3 CISC와 RISC
* `명령어 파이프라이닝`과 `슈퍼스칼라` 기법을 실제로 CPU에 적용하려면 명령어가 파이프라이닝에 최적화되어 있어야 한다. 즉, 명령어가 `파이프라이닝 하기 쉽게` 생겨야 한다.
* `파이프라이닝 하기 쉬운 명령어`란 무엇일까? 이와 관련하여 CPU의 언어인 `ISA`와 각기 다른 성격의 ISA를 기반으로 설계된 `CISC`와 `RISC`를 학습해보자.
### 명령어 집합
* CPU가 이해할 수 있는 명령어의 모음을 `명령어 집합 (instruction set)` 또는 `명령어 집합 구조 (ISA: instruction set architecture)`이라고 한다.
* 또한 CPU마다 ISA가 다를 수 있다.
	* 가령 인텔의 노트북 속 CPU는 x86 혹은 x86-64 ISA를 이해하고, 애플의 아이폰 속 CPU는 ARM ISA를 이해한다.
	* `어셈블리어`는 명령어를 읽기 편하게 표현한 언어이므로, ISA가 다르면 CPU가 이해할 수 있는 명령어가 다르다는 뜻이고, 따라서 어셈블리어도 달라진다.
* ISA가 다르면, 제어장치가 명령어를 해석하는 방식, 사용되는 레지스터의 종류와 개수, 메모리 관리 방법 등 많은 것이 달라진다. 그리고 이는 곧 CPU 하드웨어 설꼐에도 큰 영향을 미친다.
* 따라서 ISA는 CPU의 언어임과 동시에 CPU를 비롯한 하드웨어가 소프트웨어를 어떻게 이해할지에 대한 약속이라고도 볼 수 있다.
### CISC
* `CISC`는 `Complex Instruction Set Computer`의 약자이다. 이를 그대로 해석하면 `복잡한 명령어 집합을 활용하는 컴퓨터`를 의미한다. 여기서 컴퓨터를 `CPU`라고 생각해도 좋다. 앞서 소개한 x86, x86-64는 대표적인 CISC 기반의 ISA이다.
* CISC는 명령어의 형태와 크기가 다양한 `가변 길이 명령어`를 활용한다. 메모리에 접근하는 주소 지정 방식도 다양해서 아주 특별한 상황에서만 사용되는 독특한 주소 지정 방식들도 있다.
	* 다양하고 강력한 명령어를 활용한다는 말은 상대적으로 적은 수의 명령어로도 프로그램을 실행할 수 있다는 것을 의미한다.
	* 또한 이는 `컴파일된 프로그램의 크기가 작다`라는 것을 의미한다.
* 이런 장점 덕분에 `CISC`는 메모리를 최대한 아끼며 개발해야 했던 시절에 인기가 높았다.
* 하지만, CISC가 활용하는 명령어는 명령어 수행 시간이 길고 가지각색이기 때문에 파이프라인이 효율적으로 명령어를 처리할 수 없었다. 이러한 이유로 CISC 기반 CPU는 성장에 한계가 있다.
* 또한 실제로는 20% 정도의 명령어가 사용된 전체 명령어의 80% 가량을 차지한다는 것이 증명되기도 하였다.
### RISC
```
1. 원활한 파이프라이닝을 위해 `명령어 길이와 수행 시간이 짧고 규격화`되어 있어야 한다.
2. 복잡한 기능을 지원하는 명령어를 추가하기보다는 `자주 쓰이는 기본적인 명령어를 작고 빠르게 만드는 것`이 중요하다.
```
* 이러한 원칙하에 등장한 것이 `RISC (Reduced Instruction Set Computer)`이다.
* RISC는 CISC에 비해 명령어의 종류가 적고, 짧고 규격화된 명령어, 되도록 1클럭 내외로 실행되는 명령어를 지향한다.
* 즉, RISC는 `고정 길이 명령어`를 활용한다.
* 따라서 RISC 명령어 집합은 명령어 파이프라이닝에 최적화되어 있다.
* 또한 RISC는 메모리제 집적 접근하는 명령어를 `load`, `store` 두 개로 제한할 만큼 메모리 접근을 단순화하고 최소화를 추구한다. 이런 점에서 RISC를 `load-store 구조`라고 부르기도 한다.
	* 메모리 접근을 단순화, 최소화하는 대신 레지스터를 적극적으로 활용한다.
	* 그렇기에 CISC보다 레지스터를 이용하는 연산이 많고, 일반적인 경우보다 범용 레지스터 개수도 더 많다.
	* 다만 사용 가능한 명령어 개수가 CISC보다 적기 때문에, RISC는 CISC보다 많은 명령으로 프로그램을 작동시킨다.
* `ARM`은 RISC 기반의 대표적인 ISA이다.
# 06 메모리와 캐시 메모리
## 06-1 RAM의 특징과 종류
### RAM의 특징
* `RAM`에는 `실행할 프로그램의 명령어와 데이터`가 저장된다.
* 전원을 끄면 저장된 명령어와 데이터가 모두 날아간다. 이러한 저장 장치를 `휘발성 저장 장치 (volatile memory)`라고 한다.
* 반면, 전원이 꺼져도 저장된 내용이 유지되는 저장 장치는 `비휘발성 저장 장치 (non-volatile memory)`라고 한다. 
	* 하드 디스크 ,SSD, CD-ROM, USB 메모리와 같은 `보조기억장치`가 대표적인 비휘발성 저장 장치이다.
* CPU는 보조기억장치에 직접 접근하지 못한다. 그래서 일반적으로 보조기억장치인 `비휘발성 저장 장치`에는 `보관할 대상`을 저장하고, 휘발성 저장 장치인 `RAM`에는 `실행할 대상`을 저장한다. CPU가 실행하고 싶은 프로그램이 보조기억장치에 있다면 이를 RAM으로 복사하여 저장한 뒤 실행한다.
### RAM의 용량과 성능
* RAM의 용량이 적다면, 보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어진다.
* RAM의 용량이 크면 많은 프로그램들을 동시에 빠르게 실행하는 데 유리하다.
	* 다만 용량이 필요 이상으로 커졌을 때 속도가 그에 비례하여 증가하지는 않는다.
### RAM의 종류
* `RAM`의 종류에는 크게 `DRAM`, `SRAM`, `SDRAM`, `DDR SDRAM`이 있다.
#### DRAM
* `DRAM`은 `Dynamic RAM`의 준말이다.
* DRAM은 시간이 지나면 저장된 데이터가 점차 사라지는 RAM이다.
* 따라서 데이터의 소멸을 막기 위해 일정 주기로 데이터를 재활성화(다시 저장)해야 한다.
* 이러한 단점에도 불구하고 우리가 일반적으로 메모리로써 사용하는 RAM은 DRAM이다. 소비 전력이 비교적 낮고, 저렴하고, 집적도가 높기 때문에 대용량으로 설계하기가 용이하기 때문이다.
#### SRAM
* `SRAM`은 `Static RAM`의 준말이다.
* SRAM은 저장된 데이터가 변하지 않는 RAM을 의미한다.
* DRAM과 달리 시간이 지나도 데이터가 사라지지 않는다.
* 따라서 주기적으로 데이터를 재활성화할 필요도 없고, 일반적으로 속도도 더 빠르다.
* 하지만 DRAM보다 집적도가 낮고, 소비 전력도 크며, 가격도 더 비싸다. 그래서 SRAM은 `대용량으로 만들어질 필요는 없지만 속도가 빨라야 하는 저장 장치`, 가령 `캐시 메모리`에서 사용된다.
##### DRAM과 SRAM
* https://computing-jhson.tistory.com/21
* DRAM의 전기 신호 1bit를 저장하는 cell은 1개의 `트랜지스터`와 1개의 `커패시터 (capacitor, 축전기)`로 구성된다. 트랜지스터는 스위치 역할을 하며, 커패시터가 전하를 저장하면 두 전극 사이에 전업 차이가 발생하는데, 이 전압 차이에 따라 1 또는 0으로 해석된다.
    * `word line`에 전류가 흐르면 트랜지스터가 on되어 원하는 주소의 cell이 캐퍼시터와 `bit line`이 연결된다. 이때 bit line을 통해 캐퍼시터를 충전 (1bit 저장) 또는 방전 (0bit 저장)시킨다.
    * DRAM의 캐퍼시터는 시간이 지날수록 전하가 방전되어 특정 간격 (~64msec)마다 refresh 해주어야 한다.
* SRAM은 `6개`의 `트랜지스터`로 구성된다. 
	* `flip-flop 회로`를 통해 데이터를 저장한다.
	* `인버터`를 통해 셀의 상태가 유지되므로 refresh가 필요하지 않다.
* `word line`은 `row decoder`라 불리고, `bit line`은 `column decoder`라 불린다.
	* `디코더`라고 하는 이유는 이진 형태로 인코딩된 정보를 디코딩하여 메모리 셀을 선택하기 때문이다.
#### SDRAM
* `SDRAM (Synchronous Dynamic RAM)`은 `클럭 신호와 동기화된`, 발전된 형태의 `DRAM`이다.
* SDRAM은 클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고받을 수 있는 DRAM이다.
#### DDR SDRAM
* `DDR SDRAM (Double Data Rate SDRAM)`은 최근 가장 흔히 사용되는 RAM이다.
* DDR SDRAM은 `대역폭`을 넓혀 속도를 빠르게 만든 SDRAM이다.
* 여기서 `대역폭`이란 `데이터를 주고받은 길의 너비`를 의미한다.
* 한 클럭에 한 번씩 CPU와 데이터를 주고받을 수 있는 SDRAM에 비해 DDR SDRAM은` 두 배의 대역폭`으로 `한 클럭당 두 번씩` 데이터를 주고받을 수 있다. 따라서 전송 속도도 두 배가량 빠르다.
	* 이런 이유에서 한 클럭당  한 번씩 데이터를 주고받을 수 있는 SDRAM을 `SDR SDRAM (Single Data Rate SDRAM)`이라 부르기도 한다.
* SDR -> DDR2 -> DDR3 -> DDR4 순으로 대역폭이 2배씩 증가한다.
## 06-2 메모리의 주소 공간
* 주소에는 2가지 종류가 있다.
	* `물리 주소`는 메모리 하드웨어가 사용하는 주소이고,
	* `논리 주소`는 CPU와 실행 중인 프로그램이 사용하는 주소이다.
### 물리 주소와 논리 주소
* 메모리에 저장된 정보를 시시각각 변하기 떄문에, CPU와 실행 중인 프로그램은 현재 메모리 몇 번지에 무엇이 저장되어 있는지 다 알고 있는 것이 아니다.\
	* 메모리가 사용하는 `물리 주소 (physical memory)`는 말 그대로 정보가 실제로 저장된 하드웨어상의 주소를 의미한다.
	* 반면 CPU와 실행 중인 프로그램이 사용하는 `논리 주소 (logical address)`는 실행 중인 프로그램 각각에게 부여된 0번지부터 시작되는 주소를 의미한다.
* CPU가 메모리와 상호작용하려면 논리 주소와 물리 주소 간의 변환이 이루어져야 한다.
	* 논리 주소와 물리 주소 간의 변환은 `CPU`와 `주소 버스` 사이에 위치한 `메모리 관리 장치 (MMU: memory managament unit)`라는 `하드웨어`에 의해 수행된다.
	* MMU는 CPU가 발생시킨 `논리 주소`에 `베이스 레지스터 값`을 `더하여` 논리 주소를 `물리 주소`로 변환한다.
		* `베이스 레지스터`는 프로그램의 가장 작은 물리 주소, 즉 `프로그램의 첫 물리 주소`를 저장하는 셈이고,
		* `논리 주소`는 프로그램의 시작점으로부터 떨어진 `거리`인 셈이다.
### 메모리 보호 기법
* 다른 프로그램의 영역을 침범할 수 있는 명령어는 위험하기 떄문에, 논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법이 필요하다. 이는 `한계 레지스터 (limit register)`라는 레지스터가 담당한다.
* `베이스 레지스터`가 `실행 중인 프로그램의 가장 작은 물리 주소`를 저장한다면, `한계 레지스터`는 `논리 주소의 최대 크기`를 저장한다.
* 즉 프로그램의 물리 주소 범위는 `베이스 레지스터 값 이상`, `베이스 레지스터 값 + 한계 레지스터 값 미만`이 된다.
* `MMU`는 CPU가 올린 `논리 주소`를 검사하여 `한계 레지스터`보다 작은지 검사한다. 만약 작지 않으면 `인터럽트 (트랩)`을 발생시켜 실행을 중단하고, 작으면 논리주소에 `베이스 레지스터`의 값을 더하여 `물리 주소`로 변환하여 `주소 버스`로 보낸다.
* `TLB`에 대해서는 나중에 추가
## 06-3 캐시 메모리
* CPU는 프로그램을 실행하는 과정에서 `메모리`에 저장된 데이터를 빈번하게 사용한다. 하지만 CPU가 메모리에 접근하는 시간은 CPU의 연산 속도보다 느리다. 이를 극복하기 위한 저장 장치가 바로 `캐시 메모리`이다.
### 저장 장치 계층 구조

* 저장 장치는 일반적으로 아래와 같은 명제를 따른다.

```
1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다
```

* 컴퓨터가 사용하는 저장 장치들은 `CPU에 얼마나 가까운가`를 기준으로 계층적으로 나타낼 수 있다. 이를 `저장 장치 계층 구조 (memory hierarchy)` 라고 한다.
* 지금까지 배운 저장 장치 계층은 다음과 같다.
  * `레지스터` - `메모리` -`보조기억장치`

### 캐시 메모리
* `캐시 메모리`는 CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 `SRAM`기반의 저장 장치이다.

* CPU 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생했다.

* 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용하기 위해 사용한다.

* 따라서 캐시 메모리까지 반영한 저장 장치 계층 구조는 다음과 같다.

  * `레지스터` - `캐시 메모리` - `메모리` - `보조기억장치`

* 컴퓨터 내부에는 여러 캐시 메모리가 있으며, `CPU (코어)`와 가까운 순서대로 계층을 구성한다.

  * `L1 (level 1) 캐시` - `L2 캐시` - `L3 캐시` 
  * 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치해 있다.
  * 멀티 코어 프로세서에서 L1 캐시와 L2 캐시는 코어마다 고유한 캐시 메모리로 할당되고, L3 캐시는 여러 코어가 공유하는 형태로 사용된다.

* `L1 캐시`는 접근 속도를 더욱 빠르게 만들기 위해 명령어만을 저장하는 `L1I 캐시`와 데이터만을 저장하는 `L1D 캐시`로 분리하는 경우도 있다. 이를 `분리형 캐시 (split cache)`라고 한다.
### 참조 지역성 원리
* 캐시 메모리는 메모리보다 용량이 작기 떄문에 필요한 메모리의 일부를 복사하여 저장한다.
* 캐시 메모리는 CPU가 사용할 법한 대상을 `예측`하여 저장한다.
  * 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우를 `캐시 히트 (cache hit)`라고 한다.
  * 반대로 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와햐 하는 경우를 `캐시 미스 (cache miss)`라고 한다.
  * 캐시가 히트되는 비율을 `캐시 적중률 (cache hit ratio)`이라 하고 다음과 같이 계산한다.
    * `캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)`
* 캐시 메모리는 `참조 지역성의 원리 (locality of reference, principle of locality)`에 따라 메모리로부터 가져올 데이터를 결정한다.
  * 참조 지역성의 원리란 CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리이다.
#### 첫째, `최근에 접근했던 메모리 공간에 다시 접근하려는 경향`은 무엇일까?
* 변수에 값을 저장하고 나면 언제든 변수에 다시 접근하여 변수에 저장된 값을 사용할 수 있다.
* 또한 일반적으로 변수에 저장된 값은 한 번만 사용되지 않고 프로그램이 실행되는 동안 여러 번 사용된다. 
* 이렇게 `최근에 접근했던 메모리 공간에 다시 접근하려는 경향`을 `시간 지역성 (temporal locality)`라고 한다.
#### 둘째, `접근한 메모리 공간 근처를 접근하려는 경향`은 무엇일까?
* CPU가 실행하려는 프로그램은 보통 관련 데이터들끼리 한데 모여 있다.
	* 가령 매모리 내에 워드 프로세서 프로그램, 게임 프로그램이 있다고 가정해보자.
	* 각 프로그램은 서로 관련 있는 데이터끼리 모여서 저장된다.
	* 그리고 하나의 프로그램 내에서도 관련 있는 데이터들은 모여서 저장된다.
	* 따라서 CPU가 워드 프로세서 프로그램은 실행할 적에는 워드 프로세서 프로그램이 모여 있는 공간 근처를 집중적으로 접근할 것이고, 사용자가 입력을 할 때에는 입력 기능이 모여 있는 공간 근처를 집중적으로 접근할 것이다.
* 이처럼 `접근할 메모리 공간 근처를 접근하려는 경향`을 `공간 지역성 (spatial locality)`라고 한다.
# Chapter 07 보조기억장치
## 07-1 다양한 보조기억장치
### 하드 디스크
* `하드 디스크 (HDD: Hard Disk Drive)`는 자기적인 방식으로 데이터를 저장하는 보조기억장치이다. 이 때문에 하드 디스크를 `자기 디스크 (magnetic disk)`의 일종으로 지칭하기도 한다.
* 하드 디스크의 구조
  * 자기 물질로 덮여 있어 N극과 S극 (0과 1)을 저장하는 동그란 원판을 `플래터 (platter)`라고 한다.
  * 플래터 중간에서 플래터를 회전시키는 구성 요소를 `스핀들 (spindle)`이라고 한다.
    * 스핀들이 플래터를 돌리는 속드는 분당 회전수를 나타내는 `RPM (revolution per minute)`이라는 단위로 표현된다.
    * 가령 RPM이 15000인 하드 디스크는 1분에 15000바퀴를 회전하는 하드 디스크이다.
  * 플래터를 대상으로 데이터를 읽고 쓰는 구성 요소는 `헤드 (head)`이다. 헤드는 플래터 위에서 미세하게 떠 있는 채로 데이터를 읽고 쓰는, 마치 바늘같이 생긴 부품이다.
  * 그리고 헤드는 원하는 위치로 헤드를 이동시키는 `디스크 암 (disk arm)`에 부착되어 있다.
  * 하드 디스크는 여러 겹의 양면 플래터로 이뤄져 있고, 위아래로 플래터당 두 개의 헤드가 사용된다.
* 이제 플래터에 데이터가 어떻게 저장되는지 알아보자.
  * 플래터는 `트랙 (track)`과 `섹터 (sector)`라는 단위로 데이터를 저장한다.
  * 플래터를 여러 동심원으로 나눴을 때, 그중 하나를 `트랙`이라 하고 트랙을 여러 조각으로 나눴을 때 이 한 조각을 `섹터`라고 한다.
  * 하나의 섹터는 일반적으로 512 바이트 정도의 크기를 가지고 있지만, HDD의 종류에 따라 4096 바이트인 것도 있다.
  * 여러 겹의 플래터 상에서 같은 트랙이 위치한 곳을 모아 연결한 논리적 단위를 `실린더 (cylinder)`라고 한다.
    * 연속된 정보는 보통 한 실린더에 기록된다.
    * 예를 들어 2개의 플래터를 사용하는 HDD에 4개의 섹터에 걸쳐 데이터를 저장할 때는, 첫 번째 플래터의 윗면과 뒷면, 두 번째 플래터의 윗면과 뒷면에 데이터를 저장한다. 이렇게 하는 이유는 디스크 암을 움직이지 않고 바로 데이터에 접근할 수 있기 때문이다.
* HDD가 저장된 데이터에 접근하는 시간은 크게 `탐색 시간`, `회전 지연`, `전송 시간`으로 나뉜다.
  * `탐색 시간 (seelk time)`은 접근하려는 데이터가 저장된 트랙까지 헤드를 이동시키는 시간을 의미한다.
  * `회전 지언 (rotational latency)`은 헤드가 있는 곳으로 플래터를 회전시키는 시간을 의미한다.
  * `전송 시간 (transfer time)`은 HDD와 컴퓨터 간에 데이터를 전송하는 시간을 의미한다.
  * 탐색 시간과 회전 지연을 단축시키려면, 플래터를 빠르게 회전시키는 것도 중요하지만 `참조 지역성`도 중요하다.
  * 플래터의 한 면당 헤드가 하나씩 있는 HDD를 `단일 헤드 디스크`라고 하는데, 데이터에 접근하기 위해 헤드를 데이터가 위치한 트랙으로 움직여야 하기 때문에 `이동 헤드 디스크`라고도 불린다.
  * 반면 헤드가 트랙별로 달려 있는 HDD를 `다중 헤드 디스크`라고 하는데, 트랙마다 헤드가 있으므로 `탐색 시간`이 0이고, 또한 헤드를 움직이지 않으므로 `고정 헤드 디스크`라고도 불린다.
### 플래시 메모리
* USB 메모리, SD 카드, SSD는 모두 `플래시 메모리`이다.
* 플래시 메모리는 전기적으로 데이터를 읽고 쓸 수 있는 `반도체 기반`의 저장 장치이다.
* 플래시 메모리는 보조기억장치 범주에만 속한다기보다는 다양한 곳에서 널리 사용하는 저장 장치로 보는 것이 옳다. 주기억장치 중 하나인 `ROM`에도 사용된다.
  * 플래시 메모리에는 크게 `NAND 플래시 메모리`와 `NOR 플래시 메모리`가 있다. 각각 `NAND 게이트`와 `NOR 게이트`를 기반으로 만들어진 메모리를 뜻한다.
  * 이 둘 중 대용량 저장 장치로 많이 사용되는 플래시 메모리는 `NAND 플래시 메모리`이다. 또한 이번 절에서 설명하는 보조기억장치로서의 플래시 메모리 또한 NAND 플래시 메모리이다.
* 플래시 메모리에는 `셀 (cell)`이라는 단위가 있다.
	* 이 셀이 모여 MB, GB, TB의 용량을 갖는 저장 장치가 되는 것이다.
	* 한 셀에 1비트를 저장할 수 있는 플래시 메모리를 `SLC (single level cell)`타입, 한 셀에 2비트를 저장할 수 있으면  `MLC (multi level cell)`타입, 3비트는 `TLC (triple-level cell)`타입, 4비트는 `QLC`라고 한다.
#### SLC 타입
* `SLC 타입`은 한 셀로 2개의 정보를 표현 가능하다.
* 비트의 빠른 입출력이 가능하고, 수명도 길지만 용량 대비 가격이 높다.
* 따라서 보통 기업에서 데이터를 읽고 쓰기가 매우 많이 반복되며 고성능의 빠른 저장 장치가 필요한 경우에 SLC 타입을 사용한다.
#### MLC 타입
* `MLC 타입`은 한 셀로 4개의 정보를 표현 가능하다.
* SLC 타입보다 속도와 수명은 떨어지지만, 대용량화하기에 유리하다.
* 시중에서 사용되는 많은 플래시 메모리 저장 장치들은 MLC 타입 또는 TLC 타입으로 제작된다.
#### TLC 타입
* `TLC 타입`은 한 셀로 8개의 정보를 표현 가능하다.
* SLC, MLC 타입보다 속도와 수명이 떨어지지만 용량 대비 가격도 저렴하다.
#### 플래시 메모리의 가장 작은 단위인 셀보다 더 큰 단위를 알아보자
* 셀들이 모여 만들어진 단위를 `페이지 (page)`, 페이지가 모여 만들어진 단위를 `블록 (block)`, 블록이 모여 `플레인 (plane)`, 플레인이 모여 `다이 (die)`가 된다.
* 플래시 메모리에서 `읽기`와 `쓰기`는 `페이지` 단위로 이루어진다. 하지만 `삭제`는 페이지보다 큰 `블록` 단위에서 이루어진다. 읽기/쓰기 단위와 삭제 단위가 다르다는 것이 플래시 메모리의 특징이다.
	* 검색 결과 삭제 작업이 블록 단위에서 이루어지는 이유는, 셀 단위에서 삭제하는 것은 물리적으로 셀의 수명을 더욱 단축시키기 때문이라고 한다. (자세한 설명은 생략)
* 페이지는 3개의 상태를 가질 수 있다. 어떠한 데이터도 저장하지 않아 새로운 데이터를 쓸 수 있는 `Free 상태`, 이미 유효한 데이터를 가지고 있는 `Valid 상태`, 그리고 쓰레기값이라고 부르는 유효하지 않은 데이터를 저장하고 있는 `Invalid 상태`가 있다.
	* 플래시 메모리는 하드 디스크와 달리 덮어쓰기가 불가능하여 Valid 상태인 페이지에는 새 데이터를 저장할 수 없다.
	* 4개의 페이지를 가진 블록 X에 A, B 데이터가 각 페이지에 저장되어 있다고 치자.
		* 만약 새로운 데이터 C를 블록 X에 저장할 때는, 해당 블록의 빈 페이지에 저장된다.
		* 이때, A라는 데이터를 A'로 수정해 저장하게 되면, 덮어쓰기를 할 수 없으므로 남은 페이지에 A'를 저장한다. 기존의 A 데이터는 Invalid 상태가 된다.
		* 여기서 문제가 발생한다. A 데이터는 Invalid 상태인 쓰레기값임에도 불구하고 용량을 차지하고 있게 된다. 따라서 최근 SSD를 비롯한 플래시 메모리는 이런 쓰레기 값을 정리하기 위해 `가비지 컬렉션` 기능을 제공한다.
		* 가비지 컬렉션은, `유효한 페이지들만을 새로운 블록으로 복사`한 뒤, `기존의 블록을 삭제`하는 기법이다.
## 07-2 RAID의 정의와 종류
### RAID의 정의
* `RAID (redundant array of independent disks)`는 주로 하드 디스크와 SSD를 사용하는 기술로, 데이터의 안전성 혹은 높은 성능을 위해 여러 개의 물리적 보조기억장치를 마치 `하나의 논리적 보조기억장치`처럼 사용하는 기술을 의미한다.
### RAID의 종류
* RAID 구성 방법을 `RAID 레벨`이라 표현하는데, RAID 레벨에는 대표적으로 RAID 0, RAID 1, RAID 2, RAID 3, RAID 4, RAID 5, RAID 6이 있고, 그로부터 파생된 RAID 10, RAID 50 등이 있다.
	* 다만 RAID 2와 RAID 3은 현재 잘 활용되지 않는다.
#### RAID 0
* `RAID 0`은 여러 개의 보조기억장치에 데이터를 단순히 나누어 저장하는 구성 방식이다.
* 가령 1TB 하드 디스크 4개로 RAID 0을 구성했다고 가정해보자.
  * 이제 어떠한 데이터를 저장할 때, 각 하드 디스크는 번갈아 가며 데이터를 저장한다.
  * 이때 마치 줄무늬처럼 분산되어 저장된 데이터를 `스트라입 (stripe)`이라 하고, 분산하여 저장하는 것을 `스트라이핑 (striping)`이라고 한다.
  * 데이터가 스트라이핑되면, 4TB 저장 장치 1개를 읽고 쓰는 속도보다 RAID 0으로 구성된 1TB 저장 장치 4개의 속도가 이론 상 4배 가량 빠르다.
* 그런데 RAID 0으로 구성된 하드 디스크 중 하나에 문제가 생긴다면 다른 모든 하드 디스크의 정보를 읽는 데 문제가 생길 수 있다. 그래서 등장한 것이 `RAID 1`이다.
#### RAID 1
* `RAID 1`은 `복사본`을 만드는 방식이다.
* 가령 1TB 하드 디스크 4개로 RAID 1을 구성했다고 가정해보자.
	* 데이터 스트라이핑이 사용되긴 하지만, 하드 디스크를 2개로 나눠 각각 원본과 복사본으로 이용하고, 어떠한 데이터를 쓸 때는 원본과 복사본 2군데에 쓴다. 그렇기에 쓰기 속도는 RAID 0보다 느리다.
	* RAID 1 방식은 복구가 매우 간단하다는 장점이 있다.
	* 하지만 하드 디스크 개수가 한정되었을 때 사용 가능한 용량이 적어지는 단점이 있다.
	* 즉 RAID 1에서는 복사본이 만들어지는 용량만큼 사용자가 사용하지 못하게 된다. 결국 많은 양의 하드 디스크가 필요하게 되고, 비용이 증가한다는 단점으로도 이어진다.
#### RAID 4
* `RAID 4`는 RAID 1처럼 완전한 복사본을 만드는 대신 오류를 검출하고 복구하기 위한 저장 장치를 두는 구성 방식이다. 이때 `오류를 검출하고 복구하기 위한 정보`를 `패리티 비트`라고 한다. 
  * 원래 패리티 비트는 오류 검출만 가능할 뿐 오류 복구는 불가능하다. 하지만 RAID에서는 패리티 값으로 오류 수정도 가능하다.
    * 구체적인 방식은 추후에 추가
* 다만 어떤 새로운 데이터가 저장될 떄마다 패리티를 저장하는 디스크에도 데이터를 쓰게 되므로, 페리티를 저장하는 장치에 병목 현상이 생긴다는 문제점이 있다.
#### RAID 5
* `RAID 5`는 패리티 정보를 분산하여 저장하는 방식으로 RAID 4의 문제인 병목 현상을 해소한다.
#### RAID 6
* `RAID 6`의 구성은 기본적으로 RAID 5와 같으나, 서로 다른 2개의 패리티를 두는 방식이다.
* 따라서 쓰기 속도는 RAID 5보다 느리나, 더욱 안전한 구성이라고 볼 수 있다.
#### Nested RAID
* RAID 0과 RAID 1을 혼합한 `RAID 10` 방식도 있고, RAID 0과 RAID 5를 혼합한 `RAID 50` 방식도 있다. 이처럼 여러 RAID 레벨을 혼합한 방식을 `Nested RAID`라고 한다.
# Chapter 08 입출력장치
## 08-1 장치 컨트롤러와 장치 드라이버
* `장치 컨트롤러`와 `장치 드라이버`라는 개념을 통해 다양한 외부 장치가 컴퓨터 내부와 어떻게 연결되고 소통하는지 알아보자.
### 장치 컨트롤러
* 입출력 장치는 앞서 학습한 CPU, 메모리보다 다루기가 더 까다롭다. 여기에는 크게 2가지 이유가 있다.
  * 첫째, 입출력장치에는 종류가 너무나도 많다.
    * 장치마다 속도, 데이터 전송 형식 등이 다양하므로 다양한 입출력장치와 정보를 주고받는 방식을 규격화 하기가 어렵다.
  * 둘째, 일반적으로 CPU와 메모리의 데이터 전송률은 높지만 입출력장치의 데이터 전송률은 낮다.
    * 여기서 `전송률 (transfer rate)`란 데이터를 얼마나 빨리 교환할 수 있는지를 나타내는 지표이다.
    * 전송률의 차이는 CPU와 메모리, 입출력장치 간의 통신을 어렵게 한다.
    * 물론 CPU나 메모리보다 전송률이 높은 입출력장치도 있지만, 여전히 전송률이 비슷하지 않기 떄문에 어려움을 겪게 된다.
* 이와 같은 이유로 입출력장치는 컴퓨터에 직접 연결되지 않고 `장치 컨트롤러 (device controller)`라는 하드웨어에 연결된다. 
  * 장치 컨트롤러는 `입출력 제어기 (I/O controller)`, `입출력 모듈 (I/O module)` 등으로 다양하게 불리기도 한다.
* 장치 컨트롤러는 대표적으로 다음과 같은 역할을 통해 앞에서 언급한 문제들을 해결한다.
  * `CPU와 입출력장치 간의 통신 중개`
  * `오류 검출`
  * `데이터 버퍼링`
* 장치 컨트롤러의 세 번째 기능인 `데이터 버퍼링`은 무엇일까?
  * `버퍼링`이란 전송률이 높은 장치와 낮은 장치 사이에 주고받는 데이터를 `버퍼`라는 임시 저장 공간에 저장하여 전송률을 비슷하게 맞추는 방법이다.
  * 쉽게 말해 버퍼링은 `버퍼에 데이터를 조금씩 모았다가 한꺼번에 내보내거나, 데이터를 한 번에 많이 받아 조금씩 내보내는 방법`이라고 보면 된다.
* 장치 컨트롤러의 간략화된 내부 구조를 알아보자. 실제로는 더 복잡하지만, `데이터 레지스터 (data register)`와 `상태 레지스터 (status register)`, `제어 레지스터 (control register)` 세 가지를 기억하자. 상태 레지스터와 제어 레지스터는 하나의 `상태/제어 레지스터`로 사용되기도 한다.
  * `데이터 레지스터`
    * CPU와 입출력장치 사이에 주고받을 데이터가 담기는 레지스터이다.
    * 앞서 말한 `버퍼`의 역할을 데이터 레지스터가 수행한다.
    * 최근 주고받는 데이터가 많은 입출력장치에서는 레지스터 대신 `RAM`을 이용하기도 한다.
  * `상태 레지스터`
    * 입출력장치가 입출력 작업을 할 준비가 되었는지, 입출력 작업이 완료되었는지, 입출력장치에 오류는 없는지 등의 `상태 정보`가 저장된다.
  * `제어 레지스터`
    * 입출력장치가 수행할 내용에 대한 `제어 정보`와 `명령`을 저장한다.
  * 이 레지스터들에 담긴 값들은 `버스`를 타고 CPU나 다른 입출력장치로 전달되기도 하고, 장치 컨트롤러에 연결된 `입출력장치`로 전달되기도 한다.
### 장치 드라이버
* `장치 드라이버 (device driver)`란 장치 컨트롤러의 동작을 감지하고 제어함으로써 장치 컨트롤러가 컴퓨터 내부와 정보를 주고받을 수 있게 하는 `프로그램`이다.
* 프로그램이기에 당연히 실행 과정에서 메모리에 저장된다.
## 08-2 다양한 입출력 방법
* 입출력 작업을 수행하려면 CPU와 장치 컨트롤러가 정보를 주고받아야 한다. 여기에는 크게 3가지 방법이 이용된다. `프로그램 입출력`, `인터럽트 기반 입출력`, `DMA 입출력`이다.
### 프로그램 입출력
* `프로그램 입출력`은 기본적으로 프로그램 속 명령어로 입출력장치를 제어하는 방법이다.
* CPU가 프로그램 속 명령어를 실행하는 과정에서 입출력 명령어를 만나면 CPU는 입출력장치에 연결된 장치 컨트롤러와 상호작용하며 입출력 작업을 수행한다.
* 메모리에 저장된 정보를 하드 디스크에 백업하는 상황을 생각해보자. CPU는 대량 아래 과정으로 입출력 작업을 한다.
	```
	1. 우선 CPU는 하드 디스크 컨트롤러의 제어 레지스터에 쓰기 명령을 보낸다.
	2. 하드 디스크 컨트롤러는 하드 디스크 상태를 확인한다. 하드 디스크가 준비된 상태라면 하드 디스크 컨트롤러는 상태 레지스터에 준비되었다고 표시한다.
	3. CPU는 상태 레지스터를 주기적으로 읽어보며 하드 디스크의 준비 여부를 확인한다. 하드 디스크가 준비됐음을 CPU가 알게 되면 백업할 메모리의 정보를 데이터 레지스터에 쓴다. 아직 백업 작업이 완료되지 않았다면 1번부터 반복하고, 완료되었다면 작업을 종료한다.
	```
* 이렇듯 프로그램 입출력 방식에서의 입출력 작업은 CPU가 장치 컨트롤러의 `레지스터` 값을 읽고 씀으로써 이뤄진다.
	* CPU가 입출력장치의 상태는 어떤지, 처리할 데이터가 있는지를 주기적으로 확인하는 방식을 `폴링`이라고 한다.
* 하지만 CPU 내부의 레지스터와는 달리 CPU는 여러 장치 컨트롤러 속 레지스터들을 모두 알고 있기 어렵다. 그렇다면 입출력 명령어들은 어떻게 표현되고, 어떻게 메모리에 저장될까?
* 여기에는 크게 2가지 방식이 있다.
#### 메모리 맵 출력
* `메모리 맵 출력 (memory-mapped I/O)`은 메모리에 접근하기 위한 주소 공간과 입출력장치에 접근하기 위한 주소 공간을 하나의 주소 공간으로 간주하는 방법이다.
* 가령 1024 개의 주소를 표현할 수 있는 공간이 있을 때, 512개는 `메모리 주소`를, 512개는 `장치 컨트롤러의 레지스터`를 표현하기 위해 사용하는 것이다.
* 이때 CPU는 메모리의 주소들이나 장치 컨트롤러의 레지스터들이나 모두 똑같이 메모리 주소를 대하듯 하면 된다.
#### 고립형 입출력
* `고립형 입출력 (isolated I/O)`은 메모리를 위한 주소 공간과 입출력장치를 위한 주소 공간을 분리하는 방법이다.
* `제어 버스`에 `메모리 읽기/쓰기`선 이외에 `입출력장치 읽기/쓰기`선이 존재
* 메모리를 위한 주소 공간과 입출력장치에 접근하기 위한 주소 공간이 분리되어 있다.
* 따라서 메모리 주소 공간이 축소되지 않는다. 또한 입출력장치의 레지스터에 접근하기 위해 입출력 전용 명령어를 사용해야 한다.
### 입터럽트 기반 입출력
* CPU는 장치 컨트롤러에 입출력 작업을 명령하고, 장치 컨트롤러가 입출력장치를 제어하며 입출력을 수행하는 동안 CPU는 다른 일을 할 수 있다.

* 장치 컨트롤러가 입출력 작업을 끝낸 뒤 CPU에게 인터럽트 요청 신호를 보내면 CPU는 하던 일을 잠시 백업하고 `인터럽트 서비스 루틴`을 실행한다.

* 만약 여러 입출력장치로부터 인터럽트가 발생되면 CPU는 이를 어떻게 처리해야 할까?
	* CPU가 `플래그 레지스터` 속 `인터럽트 비트`를 비활성화한 채 인터럽트를 처리하는 경우, 다른 입출력장치에 의한 인터럽트를 받아들이지 않기 때문에 CPU는 순차적으로 하드웨어 인터럽트를 처리한다.
	* 하지만 CPU가 모든 인터럽트를 단순히 순차적으로만 처리할 수는 없다.
	* 따라서, 인터럽트 비트가 활성화되어 있는 경우, 또는 인터럽트 비트를 비활성화해도 무시할 수 없는 인터럽트인 `NMI (non-maskable interrupt)`가 발생한 경우 CPU는 기존 인터럽트의 실행을 잠시 멈추고 우선순위가 더 높은 인터럽트를 처리한 후, 다시 기존의 인터럽트의 실행을 재개한다.
	
* 우선순위를 반영하여 다중 인터럽트를 처리하는 방법에는 여러 가지가 있지만, 많은 컴퓨터에서는 `프로그래머블 인터럽트 컨트롤러 (PIC: Programmable Interrupt Controller)`라는 하드웨어를 사용한다.

  * `PIC`는 여러 장치 컨트롤러에 연결되어 장치 컨트롤러에서 보낸 하드웨어 인터럽트 요청들의 우선순위를 판별한 뒤 CPU에 지금 처리해야 할 하드웨어 인터럽트는 무엇인지를 알려주는 장치이다.

  * PIC에는 여러 핀이 있는데, 각 핀에는 CPU에 하드웨어 인터럽트 요청을 보낼 수 있는 약속된 하드웨어가 연결되어 있다.  

  * 가령 첫 번째 핀은 타이머 인터럽트를 받아들이는 핀, 두 번째 핀은 키보드 인터럽트를 받아들이는 핀일 수 있다.

  * PIC의 다중 인터럽트 처리 과정을 조금 더 정확히 알아보자.

    ```
    1. PIC가 장치 컨트롤러에서 인터럽트 요청 신호(들)를 받아들인다.
    2. PIC는 인터럽트 우선순위를 판단한 뒤 CPU에 처리해야 할 인터럽트 요청 신호를 보낸다.
    3. CPU는 PIC에 인터럽트 확인 신호를 보낸다.
    4. PIC는 데이터 버스를 통해 CPU에 인터럽트 벡터를 보낸다.
    5. CPU는 인터럽트 벡터를 통해 인터럽트 요청의 주체를 알게 되고, 해당 장치의 인터럽트 서비스 루틴을 실행한다.
    ```

  * 일반적으로 더 많고 복잡한 장치들의 인터럽트를 관리하기 위해 PIC를 2개 이상 `계층적`으로 구성한다.

  * 참고로 `NMI`까지 우선순위를 판별하지는 않는다.
### DMA 입출력

* 앞서 설명한 `프로그램 기반 입출력`과 `인터럽트 기반 입출력`에 공통점이 있다면, 입출력장치와 메모리 간의 데이터 이동은 CPU가 주도하고, 이동하는 데이터도 반드시 CPU를 거친다는 점이다.

* 예를 들어 입출력장치 데이터를 메모리에 저장하는 경우

  * CPU는 장치 컨트롤러에서 입출력장치 데이터를 하나씩 읽어 (CPU의)레지스터에 적재하고,
  * 적재한 데이터를 메모리에 저장한다.

* 메모리 속 데이터를 입출력장치에 내보내는 경우도 마찬가지이다.

  * CPU는 메모리에서 데이터를 하나씩 읽어 (CPU의)레지스터에 적재하고,
  * 적재한 데이터를 하나씩 입출력장치에 내보낸다.

* 이처럼 입출력장치와 메모리 사이에 전송되는 모든 데이터가 반드시 CPU를 거쳐야 한다면 가뜩이나 바쁜 CPU는 입출력장치를 위한 연산 때문에 시간을 뺏기게 된다.

* 그래서 입출력장치와 메모리가 CPU를 거치지 않고도 상호작용할 수 있는 입출력 방식인 `DMA (direct memory access)`가 등장했다.

* `DMA 입출력`을 하기 위해서는 `시스템 버스`에 연결된 `DMA 컨트롤러`라는 하드웨어가 필요하다.

#### DMA 입출력 과정

* 일반적으로 DMA 입출력은 아래와 같이 이루어진다.

  ```
  1. CPU는 DMA 컨트롤러에 입출력장치의 주소, 수행할 연산(읽기/쓰기), 읽거나 쓸 메모리의 주소 등과 같은 정보로 입출력 작업을 명령한다.
  2. DMA 컨트롤러는 CPU 대신 장치 컨트롤러와 상호작용하며 입출력 작업을 수행한다. 이때 DMA 컨트롤러는 필요한 경우 메모리에 직접 접근하여 정보를 읽거나 쓴다.
  3. 입출력 작업이 끝나면 DMA 컨트롤러는 CPU에 인터럽트를 걸어 작업이 끝났음을 알린다.
  ```

* 이번에는 메모리 내의 정보를 하드 디스크에 백업하는 작업이 DMA 입출력으로 어떻게 이루어지는지 알아보자.

  ```
  1. CPU는 DMA 컨트롤러에 하드 디스크 주소, 수행할 연산(쓰기), 백업할 내용이 저장된 메모리의 주소 등의 정보와 함께 입출력 작업을 명령한다.
  2. DMA 컨트롤러는 CPU를 거치지 않고 메모리와 직접 상호작용하며 백업할 정보를 읽어오고, 이를 하드 디스크의 장치 컨트롤러에 내보낸다.
  3. 백업이 끝나면 DMA 컨트롤러는 CPU에게 인터럽트를 걸어 작업이 끝났음을 알린다.
  ```

* 위 입출력 과정에서 알 수 있듯이 입출력장치와 메모리 사이에 주고받을 데이터는 CPU를 거치지 않는다.

* CPU는 오로지 입출력의 시작과 끝에만 관여하면 된다.

* 그런데 DMA 컨트롤러는 `시스템 버스`로 메모리에 직접 접근이 가능하지만, 시스템 버스는 CPU와 DMA 컨트롤러가 `동시에 사용하는 것이 불가능`하다. 시스템 버스는 `공용 자원`이기 떄문이다.

* 그래서 DMA 컨트롤러는 CPU가 시스템 버스를 이용하지 않을 떄마다 조금씩 시스템 버스를 이요하거나, CPU가 일시적으로 시스템 버스를 이용하지 않도록 허락을 구하고 시스템 버스를 집중적으로 이용한다.

* CPU 입장에서는 마치 버스에 접근하는 주기를 도둑 맞는 기분이 들 것이다. 그래서 이러한 DMA의 시스템 버스 이용을 `사이클 스틸링 (cycle stealing)`이라고 부른다.

#### 입출력 버스

* `DMA 컨트롤러`와 `장치 컨트롤러`의 연결 방식과 `입출력 버스`에 대해 알아보자.

* 가령 메모리 내 정보를 하드 디스크로 백업하는 상황에서

  ```
  1. 메모리에서 DMA 컨트롤러로 데이터를 가져오기 위해 시스템 버스를 한 번 사용하고
  2. DMA 컨트롤러의 데이터를 장치 컨트롤러로 옮기기 위해 시스템 버스를 또 한 번 사용한다.
  ```

* 이처럼 DMA를 위해 시스템 버스를 너무 자주 이용하면 그만큼 CPU가 시스템 버스를 이용하지 못한다.

* 이 문제는 DMA 컨트롤러와 장치 컨트롤러들을 `입출력 버스 (input/output bus)`라는 별도의 버스에 연결하여 해결할 수 있다.

* 그러면 DMA 컨트롤러와 장치 컨트롤러가 서로 데이터를 전송할 때는 시스템 버스를 이용할 필요가 없으므로 시스템 버스의 사용 빈도를 줄일 수 있다.

* 현대 컴퓨터 대부분에는 입출력 버스가 있다. 다시 말해 대부분의 입출력장치(장치 컨트롤러)는 시스템 버스가 아닌 입출력 버스와 연결된다. 이런 점에서 볼 때 입출력 버스는 `입출력장치를 컴퓨터 내부와 연결 짓는 통로`라고도 볼 수 있다.

* 입출력 버스에는 `PCI (peripheral component interconnect) 버스`, `PCI Express (PCIe) 버스` 등 여러 종류가 있다. 여러 입출력장치들을 PCIe 버스와 연결해 주는 통로인 `PCIe 슬롯`도 존재한다.

# Chapter 09 운영체제 시작하기
## 09-1 운영체제를 알아야 하는 이유
### 운영체제란

* 모든 프로그램은 하드웨어를 필요로 한다. 예를 들어 1 + 1 = 2를 계산하는 프로그램은 CPU를 필요로 하고, 이미지를 하드 디스크에 저장하는 프로그램은 하드 디스크를 필요로 한다.
* 이때 프로그램 실행에 마땅히 필요한 요소들을 가리켜 `시스템 자원`, 혹은 줄여서 `자원`이라고 한다. CPU, 메모리, 보조기억장치, 입출력장치 등과 같은 컴퓨터 부품들은 모두 자원이라고 볼 수 있다. 즉, 모든 프로그램은 실행되기 전에 반드시 자원이 필요하다.
* 여기서 실행할 프로그램에 필요한 자원을 할당하고, 프로그램이 올바르게 실행되도록 돕는 특별한 프로그램이 바로 `운영체제 (operation system)`이다.
* 운영체제도 `프로그램`이기 때문에 실행 시 `메모리`에 적재되어야 한다. 다만 운영체제는 매우 특별한 프로그램이기 때문에 항상 컴퓨터가 부팅될 때 메모리 내 `커널 영역 (kernel space)`이라는 공간에 따로 적재되어 실행된다.
  * 커널 영역을 제외한 나머지 영역, 사용자가 이용하는 `응용 프로그램`이 적재되는 영역을 `사용자 영역 (user space)`이라고 한다.
  * 즉, 운영체제는 커널 영역에 적재되어 사용자 영역에 적재된 프로그램들에 `자원`을 할당하고 이들이 올바르게 실행되도록 돕는다.
* 운영체제는 실행할 프로그램을 메모리에 적재하고, 더 이상 실행되지 않는 프로그램을 메모리에서 삭제하며 지속적으로 `메모리 자원을 관리`한다.
* 운영체제는 최대한 공정하게 여러 프로그램에 `CPU 자원을 할당`한다.
* 또한 가령 여러 프로그램이 동시에 프린터를 사용하려 할 때 운영체제는 동시에 2 개의 프로그램이 프린터를 사용하지 못하도록 막고, 하나의 프로그램이 프린터를 이용하는 동안 다른 프로그램은 기다리게 만들어 프린터 자원을 관리한다.
* 이처럼 운영체제는 `응용 프로그램`과 `하드웨어` 사이에서 응용 프로그램에 필요한 자원을 할당하고, 응용 프로그램이 올바르게 실행되도록 관리하는 역할을 맡는다.
* 운영체제는 자원 배분, 프로그램 실행 시 지켜야 할 규칙을 만들어 컴퓨터 시스템 전체를 관리하며, 관리할 자원별로 기능이 나누어져 있기도 하다.

## 09-2 운영체제의 큰 그림
### 운영체제의 심장, 커널

* OS의 핵심 서비스를 담당하는 부분을 `커널 (kernel)`이라고 한다.

* GUI나 CLI 같은 UI는 OS가 제공하는 서비스지만 커널에 포함되지는 않는다.

### 이중 모드와 시스템 호출

* OS는 사용자가 실행하는 응용 프로그램이 `하드웨어 자원`에 직접 접근하는 것을 방지하여 자원을 보호한다.

* 응용 프로그램이 자원에 접근하기 위해서는 OS에 도움을 요청해야 한다. 이때 도움을 요청한다는 말은 `운영체제 코드를 실행하려고 한다`는 말과 같다.

  * 예를 들어 응용 프로그램이 실행 과정에서 하드 디스크에 접근하여 데이터를 저장하려면 OS에 도움을 요청해야 하고, OS는 커널 영역 내의 하드 디스크에 데이터를 저장하는 `코드`를 실행하여 응용 프로그램의 작업을 대신 수행해 준다.

* `이중 모드 (dual mode)`

  * 이러한 OS의 문지기 역할은 이중 모드로써 구현된다. `이중 모드`란 `CPU가 명령어를 실행하는 모드`를 크게 `사용자 모드`와 `커널 모드`로 구분하는 방식이다. CPU는 명령어를 사용자 모드로써 실행할 수 있고, 커널 모드로써 실행할 수 있다.
  * CPU가 어떤 모드로 실행 중인지는 `플래그 레지스터` 속 `슈퍼바이저 플래그`를 보면 알 수 있다.

* `사용자 모드 (user mode)`는 OS 서비스를 제공받을 수 없는 실행 모드이다. 즉, 커널 영역의 코드를 실행할 수 없는 모드이다. 일반적인 응용 프로그램은 기본적으로 사용자 모드로 실행된다. 사용자 모드로 실행 중인 CPU는 입출력 명령어와 같이 하드웨어 자원에 접근하는 명령어를 실행할 수 없다. 그래서 사용자 모드로 실행되는 일반적인 응용 프로그램은 `자원에 접근할 수 없다`.

* 반면 `커널 모드 (kernel mode)`는 OS 서비스를 제공받을 수 있는 실행 모드이다. 즉, `커널 영역의 코드를 실행`할 수 있는 모드이다. CPU가 커널 모드로 명령어를 실행하면 자원에 접근하는 명령어를 비롯한 모든 명령어를 실행할 수 있다.

* `사용자 모드`로 실행되는 프로그램이 자원에 접근하는 OS 서비스를 제공받으려면 OS에 요청을 보내 `커널 모드로 전환`되어야 한다. 이때 OS 서비스를 제공받기 위한 요청을 `시스템 호출 (system call, 시스템 콜)`이라고 한다. 

  * `시스템 호출`은 일종의 인터럽트이다. 정확히는 `소프트웨어 인터럽트`이다.  소프트웨어 인터럽트는 인터럽트를 발생시키는 특정 명령어에 의해 발생하는 인터럽트이다.

  * 따라서 CPU가 시스템 호출을 처리하는 순서는 인터럽트 처리 순서와 유사하다. 가령 한 응용 프로그램이 하드 디스크에 데이터를 저장하는 경우

    > 1. 하드 디스크에 데이터를 저장하는 시스템 호출을 발생시켜 커널 모드로 전환하고
    > 2. 운영체제 내의 `하드 디스크에 데이터를 저장하는 코드`를 실행함으로써 하드 디스크에 접근할 수 있다.
    > 3. 그리고 하드 디스크에 접근이 끝났다면 다시 사용자 모드로 복귀하여 실행을 계속해 나간다.
  
  * 일반적으로 응용 프로그램은 실행 과정에서 OS 서비스를 매우 빈번하게 이용한다.
  
### 운영체제의 핵심 서비스
#### 프로세스 관리

* 실행 중인 프로그램을 `프로세스 (process)`라고 한다. 

* 일반적으로 하나의 CPU는 한 번에 하나의 프로세스만 실행할 수 있기에  CPU는 이 프로세스들을 조금씩 번갈아 가며 실행한다.

### 자원 접근 및 할당

* 모든 `프로세스`는 실행을 위해 `자원`을 필요로 한다. 그리고 `OS`는 프로세스들이 자원에 접근하고 조작함으로써 프로세스에 필요한 자원을 할당해 준다.

#### CPU

* 일반적으로 메모리에는 여러 프로세스가 적재되고, 하나의 CPU는 한 번에 하나의 프로세스만 실행할 수 있다. 이에 OS는 프로세스들에 공정하게 CPU를 할당하기 위해 `CPU 스케줄링`을 한다.

#### 메모리

* OS는 새로운 프로세스가 적재될 때마다 어느 주소에 적재해야 할지를 결정해야 한다.

#### 입출력장치

* `인터럽트 서비스 루틴`은 OS가 제공하는 기능으로 `커널 영역`에 있다. 입출력장치가 발생시키는 `하드웨어 인터럽트`도 마찬가지이다. 입출력장치가 CPU에 하드웨어 인터럽트 요청 신호를 보내면 CPU는 하던 일을 잠시 백업한 뒤 커널 영역에 있는 인터럽트 서비스 루틴을 실행한다.

### 파일 시스템 관리

* `파일 시스템`도 OS가 지원하는 핵심 서비스이다.

## 가상 머신과 이중 모드의 발전

* `가상 머신 (virtual machine)`이란 이름 그대로 `소프트웨어적으로 만들어낸 가상 컴퓨터`이다.
* 가상 머신을 설치하면 새로운 OS와 응용 포르개름을 설치하고 실행할 수 있다.
* 만약 컴퓨터에 설치된 OS에서 가상 머신을 설치 및 실행한다면, 그 가상 머신 또한 `응용 프로그램`이다. 그래서 `사용자 모드`로 작동한다. 마찬가지로 가상 머신에 설치된 OS도 사용자 모드로 작동하는데, 이러면 OS 서비스를 제공받기 어려울 것이다. 
* 그래서 가상화를 지원하는 CPU는 커널 모드와 사용자 모드 이외에 가상 머신을 위한 모드인 `하이퍼바이저 모드`를 따로 둔다. 
* 이로써 가상 머신 상에서 작동하는 응용 프로그램들은 하이퍼바이저 모드로써 가상 머신에 설치된 OS로부터 OS 서비스를 받을 수 있다.

# Chapter 10 프로세스와 스레드

## 10-1 프로세스 개요

* 보조기억장치에 저장된 프로그램을 메모리에 적재하고 실행하는 순간 그 프로그램은 `프로세스`가 되고, 이 과정을 `프로세스를 생성한다`라고 표현한다.

### 프로세스 직접 확인하기

* `포그라운드 프로세스 (foreground process)`, `백그라운드 프로세스 (background process)`가 존재하며, 백그라운드 프로세스 중에서도 시스템이 부팅될 때 자동으로 실행되어 시스템이 종료될 때까지 사용자와 상호작용하지 않고 작업을 지속적으로 수행하는 프로세스를 유닉스 체계의 OS에서는 `데몬 (daemon)`이라고 부르고, 윈도우 OS에서는 `서비스 (service)`라고 부른다.

### 프로세스 제어 블록

* 모든 프로세스는 실행을 위해 CPU를 필요로 하지만, CPU 자원은 한정되어 있다.
* 그렇기에 프로세스들은 자신의 차례가 되면 정해진 시간만큼의 CPU를 이용하고, 시간이 끝났음을 알리는 `타이머 인터럽트 (클럭 신호를 발생시키는 장치에 의해 주기적으로 실행되는 하드웨어 인터럽트)`가 발생하면 자신의 차례를 양보하고 다음 차례가 올 때까지 기다린다.
* OS는 빠르게 번갈아 수행되는 프로세스의 실행 순서를 관리하고, 프로세스에 CPU를 비롯한 자원을 배분한다. 이를 위해 OS는 `프로세스 제어 블록 (PCB: Process Control Block)`을 이용한다.
* PCB는 프로세스 생성 시 `커널 영역`에 생성되고, 실행이 끝나면 폐기된다. 즉 `새로운 프로세스가 생성되었다`는 말은 `OS가 PCB를 생성했다`는 말과 같고, `프로세스가 종료되었다`는 말은 `OS가 해당 PCB를 폐기했다`는 말과 같다.

#### 프로세스 ID

* `프로세스 ID (PID: Process ID)`는 특정 프로세스를 `식별하기 위한 고유한 번호`이다.

#### 레지스터 값

* 프로세스는 자신의 차례가 돌아오면 이전까지 사용했던 `레지스터`들의 중간값을 모두 복원한다. 
* 그래서 PCB 안에는 해당 프로세스가 실행하며 사용했던 프로그램 카운터를 비롯한 레지스터 값들이 담긴다.

#### 프로세스 상태

* 현재 프로세스가 어떤 상태인지도 PCB에 기록된다.

#### CPU 스케줄링 정보

* 프로세스가 언제, 어떤 순서로 CPU를 할당받을지에 대한 정보도 PCB에 기록된다.

#### 메모리 관리 정보

* 프로세스마다 메모리에 저장된 위치가 다르다. 그래서 PCB에는 프로세스가 어느 주소에 저장되어 있는지에 대한 정보가 있어야 한다. 
* PCB에는 `베이스 레지스터`, `한계 레지스터` 값과 같은 정보들이 담긴다. 
* 또한 `페이지 테이블` 정보도 PCB에 담긴다.

#### 사용한 파일과 입출력장치 목록

* 프로세스가 실행 과정에서 특정 입출력장치나 파일을 사용하면 PCB에 대한 내용이 명시된다.
* 즉 어떤 입출력장치가 이 프로세스에 할당되었는지, 어떤 파일들을 열었는지에 대한 정보들이 PCB에 기록된다.

### 문맥 교환

* 실행되던 프로세스가 CPU 사용을 양보할 때 프로세스 수행을 재개하기 위해 기억해야 할 정보를 `문맥 (context)`라고 한다. PCB에 기록되는 정보들을 문맥이라고 봐도 무방하다.
* 기존 프로세스의 문맥을 PCB에 백업하고, 새로운 프로세스를 실행하기 위해 문맥을 PCB로부터 복구하여 새로운 프로세스를 실행하는 것을 `문맥 교환 (context switching)`이라고 한다.

### 프로세스의 메모리 영역

* 프로세스가 생성되면 `커널 영역`에 `PCB`가 생성된다고 한다. 그렇다면 사용자 영역에는 프로세스가 어떻게 배치될까?
* 하나의 프로세스는 `사용자 영역`에 크게 `코드 영역`, `데이터 영역`, `힙 영역`, `스택 영역`으로 나뉘어 저장된다.

#### 코드 영역

* `코드 영역 (code segment)`은 `텍스트 영역 (text segment)`이라고도 부른다. 이곳에는 말 그래도 코드, 즉 `기계어로 이루어진 명령어`가 저장된다. 코드 영역에는 데이터가 아닌 CPU가 실행할 명령어가 담겨있기 때문에 쓰기가 금지되어 있다. 즉 코드 영역은 `읽기 전용` 공간이다.

#### 데이터 영역

* `데이터 영역 (data segment)`은 잠깐 썼다가 없앨 데이터가 아닌 `프로그램이 실행되는 동안 유지할 데이터`가 저장되는 공간이다. 이런 데이터로는 `전역 변수`가 대표적이다.
* `코드 영역`과 `데이터 영역`은 그 크기가 변하지 않기 때문에 `정적 할당 영역`이라고도 부른다.

#### 힙 영역

* `힙 영역 (heap segment)`은 사용자, 즉 프로그래머가 `직접 할당할 수 있는` 저장 공간이다.
* 프로그래밍 과정에서 힙 영역에 메모리 공간을 할당했다면 언젠가는 해당 공간을 반환해야 한다. 이는 OS에게 `더 이상 해당 메모리 공간을 사용하지 않겠다`라고 말해주는 것과 같다.
* 메모리 공간을 반환하지 않으면 메모리 낭비를 초래하게 된다. 이런 문제를 `메모리 누수 (memory leak)`라고 한다.

#### 스택 영역

* `스택 영역 (stack segment)`은 `데이터를 일시적으로 저장`하는 공간이다. 
* 데이터 영역에 담기는 값과는 달리 잠깐 쓰다가 말 값들이 저장되는 공간이다. 이런 데이터는 함수의 실행이 끝나면 사라지는 `매개 변수`, `지역 변수`가 대표적이다.
* `힙 영역`과 `스택 영역`은 프로세스 실행 과정에서 그 크기가 변할 수 있는 영역이기 때문에 `동적 할당 영역`이라고도 부른다.
* 일반적으로 `힙 영역`은 `메모리의 낮은 주소에서 높은 주소로 할당`되고, `스택 영역`은 `높은 주소에서 낮은 주소로 할당`된다.

## 10-2 프로세스 상태와 계층 구조

* OS는 `프로세스의 상태`를 `PCB`에 기록하여 `계층적`으로 관리한다.

### 프로세스 상태

#### 생성 상태

* 프로세스를 생성 중인 상태를 `생성 상태 (new)`라고 한다. 이제 막 메모리에 적재되어 PCB를 할당 받은 상태이다.
* 생성 상태를 거쳐 실행할 준비가 완료된 프로세스는 곧바로 실행되지 않고 `준비 상태`가 되어 CPU의 할당을 기다린다.

#### 준비 상태

* `준비 상태 (ready)`는 당장이라도 CPU를 할당받아 실행할 수 있지만, 아직 자신의 차례가 아니기에 기다리고 있는 상태이다.
* 준비 상태 프로세스는 차례가 되면 CPU를 할당받아 `실행 상태`가 되는데, 이 전환을 `디스패치 (dispatch)`라고 한다.

#### 실행 상태

* `실행 상태 (running)`은 CPU를 할당받아 실행 중인 상태를 의미한다.
* 실행 중인 프로세스는 할당된 일정 시간 동안만 CPU를 사용할 수 있다. 이때 프로세스가 할당된 시간을 모두 사용한다면 (`타이머 인터럽트`가 발생한다면) 다시`준비 상태`가 되고, 실행 도중 `입출력장치`를 사용하여 입출력 장치의 작업이 끝날 때까지 기다려야 한다면 `대기 상태`가 된다.

#### 대기 상태

* 프로세스는 실행 도중 입출력장치를 사용하는 경우가 있다.
* 입출력 작업은 CPU에 비해 처리 속도가 느리기에, 입출력 작업을 요청한 프로세스는 입출력장치가 입출력을 끝날 때까지 (`입출력 완료 인터럽트`를 받을 때까지) 기다려야 한다. 이렇게 입출력장치의 작업을 기다리는 상태를 `대기 상태 (blocaked)`라고 한다. 입출력 작업이 완료되면 해당 프로세스는 다시 `준비 상태`로 CPU 할당을 기다린다.
  * 입출력 작업 뿐만이 아니라 특정 이벤트를 기다릴 때 프로세스는 대기 상태가 된다.

#### 종료 상태

* `종료 상태 (terminated)`는 프로세스가 종료된 상태이다. 
* 프로세스가 종료되면 OS는 `PCB와 프로세스가 사용한 메모리를 정리`한다.

##### 프로세스 상태 다이어그램

* 자세한 그림은 생략한다.

### 프로세스 계층 구조

* 프로세스는 실행 도중 `시스테 호출`을 통해 다른 프로세스를 생성할 수 있다.

* 이때 새 프로세스를 생성한 프로세스를 `부모 프로세스`, 부모 프로세스에 의해 생성된 프로세스를 `자식 프로세스`라고 한다.

* 두 프로세스는 엄연히 다른 프로세스이기 때문에 각기 다른 `PID`를 가지고, 일부 OS에서는 자식 프로세스의 PCB에 부모 프로세스의 PID인 `PPID (Parent PID`가 기록되기도 한다.

* 컴퓨터가 부팅될 때 실행되는 최초의 프로세스가 자식 프로세스들을 생성하고, 생성된 자식 프로세스들이 새로운 프로세스를 낳는 형식으로 여러 프로세스가 동시에 실행되는데, 이 구조를 `프로세스 계층 구조`라고 한다.

  * 가령 사용자가 컴퓨터를 켜고 로그인 창을 통해 로그인 한 후 사용자 인터페이스 (bash 쉘)로 Vim 프로그램을 실행했다고 가정해보자.

    > 1. 컴퓨터를 켠 순간에 생성된 최초의 프로세스는 로그인을 담당하는 프로세스를 자식으로 생성한다.
    > 2. 로그인 프로세스는 bash 프로세스를 자식으로 생성한다.
    > 3. bash 프로세스는 Vim 프로세스를 자식으로 생성한다.

### 프로세스 생성 기법

* 결론부터 말하자면, 부모 프로세스를 통해 생성된 자식 프로세스들은 복제와 옷 갈아입기를 통해 실행된다.
  * 부모 프로세스는 `fork`를 통해 자신의 복사본을 자식 프로세스로 생성해내고,
  * 만들어진 복사본 (자식 프로세스)은 `exec`를 통해 자신의 메모리 공간을 다른 프로그램으로 교체한다.
  * `fork`와 `exec`는 `시스템 호출`이다.
* 프로세스들은 `fork`와 `exec`를 반복하며 `프로세스 계층 구조`를 이룬다.

## 10-3 스레드

* `스레드 (thread)`는 프로세스를 구성하는 실행의 흐름 단위이다.
* 하나의 프로세스는 여러 개의 스레드를 가질 수 있으며 스레드를 이용하여 하나의 프로세스에서 여러 부분을 동시에 실행할 수 있다.

### 프로세스와 스레드

* 실행의 흐름 단위가 하나인 프로세스를 `단일 스레드 프로세스`라고 한다.
* 하지만 `스레드`라는 개념이 도입되면서, 프로세스를 구성하는 여러 명령어들을 동시에 실행할 수 있게 되었다.
* 스레드는 실행에 필요한 최소한의 정보 (프로그램 카운터를 포함한 레지스터, 스택)만을 유지한 채 프로세스 자원을 공유하며 실행된다.
* 최근 많은 OS는 CPU에 처리할 작업을 전달할 때 프로세스가 아닌 스레드단위로 전달한다. 그리고 스레드는 프로세스 자원을 공유한 채 실행에 필요한 최소한의 정보만으로 실행된다.
* 리눅스에서는 프로세스와 스레드 모두 `실행의 문맥 (context of execution)`이라는 점에서 동등하다고 간주하고 이 둘을 크게 구분 짓지 않는다. 프로세스와 스레드라는 말 대신 `태스크 (task)`라는 이름으로 통일하여 명명한다.

### 멀티프로세스와 멀티스레드

* 여러 프로세스를 동시에 실행하는 것을 `멀티프로세스 (multiprocess)`, 그리고 여러 스레드로 프로세스를 동시에 실행하는 것을 `멀티스레드 (multithread)`라고 한다.
* 멀티프로세스 vs 멀티스레드
  * 가령 "hello"를 화면에 출력하는 간단한 프로그램을 fork를 세 번하여 실행하는 것과 스레드를 세 개 만들어 실행하는 것은 결과가 동일할테지만, 전자의 경우 코드 영역, 데이터 영역, 힙 영역 등을 비롯한 모든 자원이 복제되어 메모리에 적재되기 때문에 어찌 보면 공간이 낭비되는 것일 수 있다.
    * fork를 한 직후 같은 프로세스를 통째로 메모리에 중복 저장하지 않으면서 동시에 프로세스끼리 자원을 공유하지 않는 방법도 있는데, 이를 `쓰기 시 복사 (copy on write)` 기법이라고 한다.
  * 반면 스레드는 프로세스 자원을 공유함으로써 메모리를 더 효율적으로 사용 가능하고, 서로 간의 협력과 통신에 유리하다.
    * 다만 하나의 스레드에 문제가 생기면 다른 스레드에도 영향을 끼칠 수 있기 때문에 프로세스 전체에 문제가 생길 수 있다는 단점이 있다.
  * 물론 프로세스도 `프로세스 간 통신 (IPC: Inter-Process Communication)`을 통해 자원을 공유하고 데이터를 주고받을 수 있다.
* 참고자료
  * https://peonyf.tistory.com/entry/%EC%93%B0%EB%A0%88%EB%93%9C%EC%99%80-TCB


# Chapter 11 CPU 스케줄링

## 11-1 CPU 스케줄링 개요

* OS가 프로세스들에게 공정하고 합리적으로 `CPU 자원을 배분`하는 것을 `CPU 스케줄링 (CPU scheduling)`이라고 한다.

### 프로세스 우선순위

* 프로세스마다 `우선순위`가 다르다.
* 대부분의 프로세스들은 `CPU`와 `입출력장치`를 모두 사용하며 실행된다. 즉, 프로세스는 `실행 상태`와 `대기 상태`를 반복하며 실행된다.
  * 그런데 프로세스 종류마다 입출력장치를 이용하는 시간과 CPU를 이용하는 시간의 양에는 차이가 있다.
  * 비디오 재생이나 디스크 백업 작업을 담당하는 프로세스와 같이 입출력 작업이 많은 프로세스를 `입출력 집중 프로세스 (I/O bound process)`라고 하고, 복잡한 수학 연산, 컴파일, 그래픽 처리 작업을 담당하는 프로세스와 같이 CPU 작업이 많은 프로세스를 `CPU 집중 프로세스 (CPU bound process)`라고 한다.
  * `입출력 집중 프로세스는` 실행 상태보다는 입출력을 위한 `대기 상태`에 더 많이 머무르고, `CPU 집중 프로세스`는 대기 상태보다는 `실행 상태`에 더 많이 머무른다.
* CPU를 이용하는 작업을 `CPU 버스트 (CPU burst)`라 하고, 입출력장치를 기다리는 작업을 `입출력 버스트 (I/O burst)`라 부른다. 즉, 프로세스는 일반적으로 CPU 버스트와 입출력 버스트를 반복하며 실행된다고 볼 수 있다.
  * 따라서 입출력 집중 프로세스는 입출력 버스트가 많은 프로세스, CPU 집중 프로세스는 CPU 버스트가 많은 프로세스라고 정의할 수 있다.
* 따라서 `입출력 집중 프로세스`를 가능한 빨리 실행시켜 입출력장치를 끊임없이 작동시키고, 그 다음 `CPU 집중 프로세스`에 집중적으로 CPU를 할당하는 것이 효율적이다.
* 입출력 장치가 입출력 작업을 완료하기 전까지는 입출력 집중 프로세는 어차피 `대기 상태`가 될 예정이기 때문에 입출력 집중 프로세스를 얼른 먼저 처리해 버리고 다른 프로세스가 CPU를 사용할 수 있도록 하는 것이 바람직하다.
* 따라서 OS는 각 프로세스의 `PCB`에 `우선순위`를 명시하고, PCB에 적힌 우선순위를 기준으로 먼저 처리할 프로세스를 결정한다.
  * 유닉스 체계 OS에서는 `ps -el` 명령을 통해 프로세스의 우선순위를 확인할 수 있다.

### 스케줄링 큐

* PCB에 우선순위가 적혀 있다고는 하지만, CPU를 사용할 다음 프로세스를 찾기 위해 운영체제가 일일이 모든 프로세스의 PCB를 확인하는 것은 비효율적이다.
  * 이는 비단 CPU 자원에만 국한된 상황이 아니다.
* 그래서 OS는 각 자원을 사용하고 싶은 프로세스들을 모두 줄 세우고 이를 `스케줄링 큐 (scheduling queue)`로 구현하고 관리한다.
* OS가 관리하는 `큐`에는 다양한 종류가 있다.
  * `준비 큐 (ready queue)`는 CPU를 이용하기 위해 `준비 상태`에 접어든 프로세스들이 서는 줄을 의미하고,
  * `대기 큐 (waiting queue)`는 입출력장치를 이용하기 위해 `대기 상태`에 접어든 프로세스들이 서는 줄을 의미한다.
  * 최초에 `생성 상태`의 프로세스가 생성되면, `준비 상태`가 되어 준비 큐에 삽입되고, `디스패치`를 통해 `실행 상태`가 된다.
    * 이후 실행 시간이 완료되어 `타이머 인터럽트`가 발생하면 다시 `준비 상태`가 되어 `준비 큐`에 삽입되고,
    * 또는 입출력장치를 요청하게 되면 `대기 상태`가 되어 `대기 큐`에 삽입되어, 입출력 완료 `인터럽트`가 발생하면 다시 `준비 상태`가 되어 `준비 큐`에 삽입된다.
    * 또는 `실행 상태` 이후 프로세스가 종료되어 `종료 상태`가 될 수 있다.
* 큐는 항상 선입선출 방식으로 작동하는 것은 아니고, 우선순위가 높은 프로세스는 다른 것들보다 먼저 처리될 수 있다.

### 선점형과 비선점형 스케줄링

* `선점형 스케줄링 (preemtive scheduling)`은 프로세스가 CPU를 비롯한 자원을 사용하고 있더라도 `OS`가 프로세스로부터 `자원을 강제로 배앗아 다른 프로세스에 할당`할 수 있는 스케줄링 방식을 의미한다.
  * 여러 프로세스들에 골고루 자원을 배분할 수 있다는 장점이 있지만, 그만큼 문맥 교환 과정에서 오버헤드가 발생할 수 있다.
* 반면 `비선점형 스케줄링 (non-preemtive scheduling)`은 하나의 프로세스가 `자원 사용을 독점`할 수 있는 스케줄링 방식이다.
  * 문맥 교환의 횟수가 선점형 스케줄링보다는 적지만 모든 프로세스가 골고루 자원을 사용할 수 없다.

## 11-2 CPU 스케줄링 알고리즘

### 스케줄링 알고리즘의 종류

#### 선입 선처리 스케줄링

* `선입 선처리 스케줄링`은 `FCFS 스케줄링 (First Come First Served Scheduling)`이라고도 부른다.
* 이는 단순히 `준비 큐에 삽입된 순서대로` 프로세들을 처리하는 `비선점형 스케줄링` 방식이다.
* CPU 이용 시간이 긴 프로세스에 의해 이용 시간이 짧은 프로세스들이 기다려 `평균 대기 시간`이 길어지는 현상인 `호위 효과 (convoy effect)`가 일어날 수 있다.

#### 최단 작업 우선 스케줄링

* 준비 큐에 삽입된 프로세스들 중 `CPU 이용 시간의 길이가 짧은 프로세스부터 실행`하는 스케줄링 방식을 `최단 작업 우선 스케줄링` 혹은 `SJF 스케줄링 (Shortest Job First Scheduling)`이라고 한다.
* 기본적으로 `비선점형 스케줄링` 알고리즘으로 분류되지만, `선점형`으로 구현될 수도 있다.

#### 라운드 로빈 스케줄링

* `라운드 로빈 스케줄링 (round robin scheduling)`은 `선입 선처리` 스케줄링에 `타임 슬라이스`라는 개념이 더해진 스케줄링 방식이다.
* `선점형 스케줄링` 방식이다.
* `타임 슬라이스`란 각 프로세스가 CPU를 사용할 수 있는 정해진 시간을 의미한다.
* 만약 타임 슬라이스가 지나치게 크면 `호위 효과`가 발생할 수 있고, 지나치게 작으면 `문맥 교환`에 발생하는 비용이 커질 수 있다.

#### 최소 잔여 시간 우선 스케줄링

* `최소 잔여 시간 우선 스케줄링` 혹은 `SRT (Shortest Remaing Time) 스케줄링`은 `SJF 스케줄링` 알고리즘과 `라운드 로빈` 알고리즘을 합친 `선점형 스케줄링` 방식이다.

#### 우선순위 스케줄링

* `우선순위 스케줄링 (priority scheduling)`은 프로세스들에 `우선순위`를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 스케줄링 알고리즘이다.
* 앞서 설명한 `SJF 스케줄링`, `SRT 스케줄링`은 넓은 의미에서 우선순위 스케줄링의 일종으로 볼 수 있다.
* 다만 우선순위 스케줄링은 근본적인 문제를 내포하고 있다. 바로 우선순위가 낮은 프로세스의 실행이 계속해서 연기되는 `기아 (starvation)` 현상이 발생할 수 있다.
  * 이를 방지하기 위한 대표적인 기법으로 `에이징 (aging)`이 있다. 이는 `오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식`이다.

#### 다단계 큐 스케줄링

* `다단게 큐 스케줄링 (multilevel queue scheduling)`은 `우선순위 스케줄링`의 발전된 형태이다.
* `우선순위별로 준비 큐를 여러개 사용`하는 스케줄링 방식이다.
* 우선순위가 가장 높은 큐에 있는 프로세스들을 먼저 처리하고, 우선순위가 가장 높은 큐가 비어 있으면 그다음 우선순위 큐에 있는 프로세스들을 처리한다.
* 가령 입출력 집중 프로세스와 CPU 집중 프로세스가 각각 다른 큐에 삽입되어 처리될 수 있다.
* 큐마다 다른 스케줄링 알고리즘을 사용할 수 있다.

#### 다단계 피드백 큐 스케줄링

* 앞서 설명한 `다단계 큐 스케줄링`에서는 프로세스들이 큐 사이를 이동할 수 없어, `기아` 현상이 일어날 수 있다.
* 이를 보완한 스케줄링 알고리즘이 `다단계 피드백 큐 스케줄링 (multilevel feedback queue scheduling)`이다.
* 프로세스들이 큐 사이들을 이용할 수 있다.
  * 가령 우선순위 0 큐에서 정해진 `타임 슬라이스` 동안 실행을 다 못 끝냈다면, 우선순위 1 큐로 이동시킨다.
    * CPU를 오래 사용하는 CPU 집중 프로세스들은 자연스레 우선순위가 낮아지고, CPU를 비교적 적게 사용하는 입출력 집중 프로세스들은 자연스레 우선순위가 높은 큐에서 실행이 끝난다.
  * 또한 우선순위가 낮은 큐에서 너무 오래 기다리고 있는 프로세스는 `에이징` 기법을 적용하여 높은 우선순위의 큐로 이동시킴으로써 `기아` 현상을 예방할 수 있다.

# Chapter 12 프로세스 동기화

## 12-1 동기화란

* 동시다발적으로 협력하여 실행되는 프로세스들은 `실행 순서와 자원의 일관성을 보장`해야 하기에 반드시 `동기화 (synchronization)`되어야 한다.

### 동기화의 의미

* `프로세스 동기화`란 프로세스들 사이의 수행 시기를 맞추는 것을 의미한다.
  * `실행 순서 제어`: 프로세스를 올바른 순서대로 실행하기
  * `상호 배제`: 동시에 접근해서는 안 되는 자원에 하나의 프로세스만 접근하게 하기
* 프로세스뿐만이 아니라 스레드 등 실행의 흐름을 갖는 모든 것은 동기화의 대상이다. 다만 여기서는 `프로세스 동기화`를 일컫도록 하겠다.

#### 첫째, 실행 순서 제어를 위한 동기화

* 가령 Book.txt를 읽는 Reader 프로세스는 Writer 프로세스의 실행이 끝난 후 실행되는 것이 올바른 실행 순서이다. 이렇게 프로세스를 올바른 순서대로 실행하는 것이 첫 번째 프로세스 동기화이다.

#### 둘째, 상호 배제를 위한 동기화

* `상호 배제 (mutual exclusion)`는 `공유가 불가능한 자원의 동시 사용을 피하기 위해 사용하는 알고리즘`이다.
* (책에 나온 간단한 예시는 생략)

### 생산자와 소비자 문제

* 생산자
  ```
    register1 = count
    register1 = register1 + 1
    count = register1
  ```

* 소비자
  ```
  register2 = count
  register2 = register2 - 1
  count = register2
  ```

* 만약 2개의 기계어가 차례대로 실행되면 문제가 없겠지만, 인터럽트가 발생하여 순서가 뒤섞이게 되면 잘못된 결과가 산출될 수 있다.

### 공유 자원과 임계 구역

* `공유 자원 (shared resource)`는 전역 변수가 될 수도 있고, 파일이 될 수도 있고, 입출력장치, 보조기억장치가 될 수도 있다.
* 그리고 공유 자원 중에는 2개 이상의 프로세스를 동시에 실행하면 문제가 발생하는 자원이 있다.
* 이렇게 동시에 실행하면 문제가 발생하는 자원에 접근하는 `코드 영역`을 `임계 구역 (critical section)`이라고 한다.
  * 2 개 이상의 프로세스가 임계 구역에 진입하고자 하면 둘 중 하나는 대기해야 한다.
* `레이스 컨디션 (race condition)`은 2 개 이상의 프로세스 혹은 스레드가 공유 자원을 서로 사용하려고 `경합 (race)`하는 현상을 의미한다.
* `OS`는 이러한 `임계 구역 ` 문제를 아래 3가지 원칙 하에 해결한다. 즉, `상호 배제를 위한 동기화`를 위해서는 아래 3가지 원칙이 반드시 지켜져야만 한다.
  * `상호 배제 (mutual execlusion)`: 한 프로세스가 임계 구역에 진입했다면 다른 프로세스는 임계 구역에 들어올 수 없다.
  * `진행 (progress)`: 임계 구역에 어떤 프로세스도 진입하지 않았다면 임계 구역에 진입하고자 하는 프로세스는 들어갈 수 있어야 한다.
  * `유한 대기 (bounded waiting)`: 한 프로세스가 임계 구역에 진입하고 싶다면 그 프로세스는 언젠가는 임계 구역에 들어올 수 있어야 한다. (임계 구역에 들어오기 위해 무한정 대기해서는 안 된다.)

## 12-2 동기화 기법

* 동기화를 위한 대표적인 도구인 `뮤텍스 락`, `세마포`, `모니터`에 대해 알아보자.

### 뮤텍스 락

* `뮤텍스 락 (Mutex lock: MUTual EXclusion lock)`

  * 좌물쇠 역할: 프로세스들이 공유하는 `전역 변수 lock`
  * 임계 구역을 잠그는 역할: `acquire 함수`
  * 임계 구역의 잠금을 해제하는 역할: `release 함수`

```C
acquire() {
	while (lock == true)
		;
	lock = true;
}

release() {
	lock = false;
}

// 아래와 같은 방식으로 하나의 프로세스만 임계 구역에 진입할 수 있다.

acquire();
// 임계 구역
release();
```

* acquire 함수에서 임게 구역이 잠겨 있을 경우 프로레스가 반복적으로 lock을 확인하는 것과 같은 대기 방식을 `바쁜 대기 (busy wait)`라고 한다.

### 세마포

* `세마포 (semaphore)`는 뮤텍스 락과 비슷하지만, 조금 더 일반화된 방식의 동기화 도구이다.

  * 뮤텍스 락과 비슷한 `이진 세마포 (binary semaphore)`와 `카운팅 세마포 (counting semaphore)`가 있다. 여기서는 여러 공유 자원을 다룰 수 있는 카운팅 세마포를 다루겠다.

* 세마포의 요소

  * 임계 구역에 진입할 수 있는 프로세스의 개수 (사용 가능한 공유 자원의 개수)를 나타내는 `전역 변수 S`
  * 임계 구역에 들어가도 좋은지, 기다려야 할지를 알려주는 `wait 함수`
  * 임계 구역 앞에서 기다리는 프로세스에 '이제 가도 좋다'고 신호를 주는 `signal 함수`

```C
wait () {
	while (S <= 0)
		;
	S--;
}

signal() {
	S++;
}


// 아래와 같은 방식으로 S개의 프로세스가 임계 구역에 진입할 수 있다.

wait();
// 임계 구역
signal();
```

* 위 코드에서는 뮤텍스 락과 마찬가지로 `바쁜 대기`가 일어난다는 문제가 존재한다.
* 따라서 wait와 signal 함수를 새롭게 정의하여 `바쁜 대기`를 피할 수 있다.

``` C
wait() {
    // 해당 방식에서는 S값이 음수가 될 수 있다.
    // S가 음수인 경우 S의 절댓값은 대기 중인 프로세스의 수를 뜻한다.
    S--;
    if (S < 0) {
        add this process to Queue; // 해당 프로세스 PCB를 대기 큐에 삽입한다.
        sleep(); // 대기 상태로 접어든다.
    }
}

signal() {
    S++;
    if (S <= 0) { // 등호가 붙은 이유는, S++ 연산이 먼저 수행되었기 때문에
        remove a process p from Queue; // 대기 큐에 있는 프로세스 p를 제거한다.
        wakeup(p); // 프로세스 p를 대기 상태에서 준비 상태로 만든다.
    }
}
```

* wait, signal 함수들의 호출 순서를 조작하여 동시에 실행되는 프로세스의 실행 순서를 제어할 수 있다.

### 모니터

* `세마포`는 훌륭한 프로세스 동기화 도구이지만, 매번 임계 구역 앞뒤로 일일이 `wait`와 `signal` 함수를 명시하는 것은 번거로운 일이다.
* 이에 최근에 등장한 동기화 도구가 `모니터 (monitor)`이다.
* 모니터는 `공유 자원`과 공유 자원에 접근하기 위한 `공유 자원 연산 (인터페이스)`를 묶어 관리한다.
* 그리고 프로세스는 반드시 `인터페이스를 통해서만 공유 자원에 접근`하도록 한다.
* 모니터는 `실행 순서 제어`를 위해 특정 조건을 바탕으로 프로세스를 실행하고 일시 중단하기 위해 `조건 변수 (conditional variable)`를 사용하기도 한다.
  * 조건 변수로는 `wait`와 `signal` 연산을 수행할 수 있다.
    * `wait`를 통해 조건 변수를 위한 대기 큐에 삽입될 수 있고,
    * `signal`을 통해 큐에 삽입된 프로세스의 실행을 재개할 수 있다.
  * 다만 모니터 안에는 하나의 프로세스만이 있을 수 있기 때문에, wait를 호출했던 프로세스는 signal을 호출한 프로세스가 모니터를 떠난 뒤에 실행되거나, signal을 호출한 프로세스의 실행을 일시 중단하고 자신이 실행된 뒤 다시 signal을 호출한 프로세스의 수행을 재개한다.

# Chapter 13 교착 상태

## 13-1 교착 상태란

* 2 개 이상의 프로세스가 각자 가지고 있는 자원을 무작정 기다린다면 그 어떤 프로세스도 더이상 진행할 수 없는 `교착 상태 (deadlock)`가 된다.

### 식사하는 철학자 문제

* `식사하는 철학자 문제 (dining philosophers problem)`
* (자세한 설명은 생략한다.)
  * 철학자는 `프로세스` 혹은 `스레드`
  * 포크는 `자원`
  * 생각하는 행위는 `자원을 기다리는 것`에 빗대어 볼 수 있다.
  * 그리고 포크는 한 번에 하나의 프로세스 혹은 스레드만 접근할 수 있으니 `임계 구역`이라고도 볼 수 있다.
* 모든 철학자가 왼쪽 포크를 집어들게 되면, `교착  상태`에 빠지게 된다.

### 자원 할당 그래프

* 교착 상태는 `자원 할당 그래프 (resource-allocation graph)`를 통해 단순하게 표현할 수 있다.

* 자원 할당 그래프는 어떤 프로세스가 어떤 자원을 사용하고 있고, 또 어떤 프로세스가 어떤 자원을 기다리고 있는지를 표현하는 간단한 그래프이다.

* 자원 할당 그래프는 아래와 같은 규칙으로 그려진다.
  > 1. `프로세스`는 `원`으로, `자원의 종류`는 `사각형`으로 표현한다.
  > 2. `사용할 수 있는 자원의 개수`는 자원 `사각형 내의 점`으로 표현한다.
  > 3. 프로세스가 어떤 `자원을 할당받아 사용 중`이라면 `자원에서 프로세스를 향해 화살표`를 표시한다.
  > 4. 프로세스가 어떤 `자원을 기다리고` 있다면 `프로세스에서 자원으로 화살표`를 표시한다.

### 교착 상태 발생 조건

* 교착 상태가 발생할 조건은 4가지가 있는데, 바로 `상호 배제`, `점유와 대기`, `비선점`, `원형 대기`이다.

#### 상호 베제

* 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없을 때, 즉 `상호 배제 (mutual exclusion)` 상황에서 교착 상태가 발생할 수 있다.

#### 점유와 대기

* 자원을 할당받은 상황에서 다른 자원을 할당받기를 기다리는 상태를 `점유와 대기 (hold and wait)`라고 한다.

#### 비선점

* 프로세스가 자원을 `비선점 (nonpreemptive)`할 때 교착 상태가 발생할 수 있다.

#### 원형 대기

* 자원 하당 그래프가 원의 형태로 그려지면 교착 상태가 발생할 수 있다. 이처럼 프로세스들이 원의 형태로 자원을 대기하는 것을 `원형 대기 (circular wait)`라고 한다.

## 13-2 교착 상태 해결 방법

* OS가 교착 상태를 해결하는 방법에는 크게 3가지가 존재한다. `예방`, `회피`, `검출 후 회복`이다.

### 교착 상태 예방

* 교착 상태 발생 필요 조건 네 가지 중 하나를 충족하지 못하게 함으로써 교착 상태를 `예방`할 수 있다.
  * 자원의 `상호 배제` 없애기
    * 하지만 현실에서 사용하기에는 다소 무리가 있다.
  * `점유와 대기` 없애기
    * 자원의 활용률이 낮아질 우려가 있다.
    * 점유와 대기를 금지하면 한 프로세스에 필요한 자원을 몰아주게 되는데, 이는 당장 자원이 필요해도 기다릴 수밖에 없는 프로세스와 사용되지 않으면서 오랫동안 할당되는 자원을 다수 양산하게 된다.
  * `비선점` 조건 없애기
    * CPU와 같이 선점하여 사용할 수 있는 일부 자원에 대해서는 효과적이다.
    * 하지만 모든 자원이 이렇게 선점 가능한 것은 아니다. 가령 프린터를 이용하는 도중에 다른 프로세스가 프린터 자원을 빼앗아 사용하기란 어렵다.
    * 따라서 다소 범용성이 떨어지는 방안이다.
  * `원형 대기` 조건 없애기
    * 모든 자원에 번호를 붙이고, 오름차순으로 자원을 할당하면 원형 대기는 발생하지 않는다.
    * 가령 `식사하는 철학자` 문제에서, 모든 포크에 1번부터 5번까지 번호를 붙이고, 철학자들로 하여금 오름차순으로 포크를 집어들도록 한다면, 마지막 철학자는 5번 포크를 든 뒤 1번 포크를 들 수 없기 때문에 원형 대기가 발생하지 않게 된다.
    * 컴퓨터 시스템 내의 모든 자원에 번호를 붙이는 일은 간단한 작업이 아니고, 어떤 방식으로 번호를 부여할 것인지에 대한 문제도 존재한다.
* 이처럼 `예방` 방식은 교착 상태가 발생하지 않음을 보장할 수는 있지만 여러 부작용이 따른다.

### 교착 상태 회피

* `교착 상태 회피`는 교착 상태가 발생하지 않을 정도로만 자원을 할당한다.
* 교착 상태 회피 방식에서는 교착 상태를 할당된 자원의 무분별한 할당으로 인해 발생하는 문제로 간주한다.
* 교착 상태 회피 방식을 학습하기 위해서 알아야 할 용어들이 있다.
  * `안전 상태 (safe state)`
    * 교착 상태가 발생하지 않고 모든 프로세스가 정상적으로 자원을 할당받고 종료될 수 있는 상태
  * `불안전 상태 (unsfae state)`
    * 교착 상태가 발생할 수도 있는 상황
  * `안전 순서열 (safe sequence)`
    * 교착 상태 없이 안전하게 프로세스들에 자원을 할당할 수 있는 순서
* 즉, `안전 순서열`이 존재하는 상태를 `안전 상태`, 존재하지 않는 상태를 `불안전 상태`라고 한다.
* 따라서 OS가 교착 상태를 `회피`하기 위해서는 시스템 상태가 `안전 상태에서 안전 상태로 움직이는 경우에만 자원을 할당`하면 된다.

### 교착 상태 검출 후 회복

* 교착 상태 `검출 후 회복`은 교착 상태 발생을 인정하고 사후에 조치하는 방식이다.
* 검출 후 회복 방식에서 OS는 프로세스들이 자원을 요구할 때마다 그때그때 모두 할당하며, 교착 상태 발생 여부를 주기적으로 검사한다. 그리고 교착 상태가 검출되면 그때 비로소 다음과 같은 방식으로 회복한다.
  * `선점을 통한 회복`
    * 선점을 통한 회복은 교착 상태가 해결될 때까지 한 프로세스씩 다른 프로세스로부터 자원을 강제로 빼앗아 자원을 몰아주는 방식이다.
  * `프로세스 강제 종료를 통한 회복`
    * 교착 상태에 놓인 프로세스를 `모두 강제 종료`할 수 있다.
      * 많은 프로세스들이 작업 내역을 잃게 될 가능성이 있다.
    * 교착 상태가 없어질 때까지 `한 프로세스 씩 강제 종료`할 수도 있다.
      * 교착 상태가 없어졌는지 여부를 확인하는 과정에서 오버헤드를 야기하게 된다.

### 타조 알고리즘

* 교착 상태를 아예 무시하는 `타조 알고리즘`이라는 방법도 있다.

# Chapter 14 가상 메모리

## 14-1 연속 메모리 할당

* 프로세스에 연속적인 메모리 공간을 할당하는 방식을 `연속 메모리 할당` 방식이라고 한다.

### 스와핑

* 메모리에 적재된 프로세스들 중에는 현재 실행되지 않는 프로세스가 있을 수 있다.
* 입출력 작업의 요구로 대기 상태가 된 프로세스라던지, 오랫동안 사용되지 않은 프로세스가  이런 프로세스들에 속한다.
* 이런 프로세스들을 임시로 `보조기억장치`의 일부 영역으로 쫓아내고, 그렇게 해서 생긴 메모리상의 빈 공간에 또 다른 프로세스를 적재하여 실행하는 방식을 `스와핑 (swapping)`이라고 한다.
* 이때 프로세스들이 쫓겨나는 보조기억장치의 일부 영역을 `스왑 영역 (swap space)`이라고 한다.
* 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것을 `스왑 아웃 (swap-out)`, 반대로 스왑 영역에 있던 프로세스가 다시 메모리로 옮겨오는 것을 `스왑 인 (swap-in)`이라고 한다.
  * 스왑 아웃된 프로세스가 다시 스왑 인될 때는 스왑 아웃되기 전의 물리 주소와는 다른 주소에 적재될 수 있다.
* 스와핑을 이용하면 프로세스들이 요구하는 메모리 주소 공간의 크기가 실제 메모리 크기보다 큰 경우에도 프로세스들을 동시에 실행할 수 있다.

### 메모리 할당

* 비어 있는 메모리 공간에 프로세스를 연속적으로 할당하는 방식에는 대표적으로 `최초 적합`, `최적 적합`, `최악 적합`의 세 가지 방식이 있다.

#### 최초 적합

* `최초 적합 (first fit)`은 OS가 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 공간을 발견하면 그 공간에 프로세스를 배치하는 방식이다.
* 검색을 최소화할 수 있고 결과적으로 빠른 할당이 가능하다.

#### 최적 접합

* `최적 적합 (best fit)`은 OS가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 `가장 작은 공간`에 프로세스를 배치하는 방식이다.

#### 최악 적합

* `최악 적합 (worst fit)`은 OS가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 `가장 큰 공간`에 프로세스를 배치하는 방식이다.

### 외부 단편화

* 프로세스를 메모리에 연속적으로 배치하는 `연속 메모리 할당`은 언뜻 당연하게 느껴질 수 있지만, `외부 단편화 (external fragmentation)`라는 문제를 내포하고 있다.
* 프로세스들을 메모리에 적재했을 때, 각 프로세스들의 실행이 끝나면 메모리에 빈 공간이 생기게 된다.
* 이때 `외부 단편화` 현상이 일어날 수 있다.
  * 가령 각각 20MB, 30MB 크기의 빈 공간이 떨어져있을 때, 메모리 공간의 크기의 총합이 50MB이더라도, 50MB 크기의 프로세스를 적재할 수 없다.
* 이렇게 프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상을 `외부 단편화`라고 한다.
* 외부 단편화를 해결할 수 있는 대표적인 방안으로 메모리를 `압축 (compaction)`하는 방법이 있다. 
  * `메모리 조각 모음`이라고도 부른다. 
  * 메모리 내에 저장된 프로세스들을 적당히 재배치시켜 여기저기 흩어져 있는 작은 빈 공간들을 하나의 큰 공간으로 만드는 방법이다.
  * 다만 압축 방식은 여러 단점이 있다. 이에 외부 단편화를 없앨 수 있는 또 다른 해결 방안이 등장했는데, 이것이 오늘날까지도 사용되는 `가상 메모리 기법`, 그 중에서도 `페이징 기법`이다.

## 14-2 페이징을 통한 가상 메모리 관리

* `연속 메모리 할당`은 2 가지 문제를 내포하고 있다.
  * 한 가지는 `외부 단편화`이고,
  * 또 하나는 물리 메모리보다 큰 프로세스를 실행할 수 없다는 것이다. 가령 4GB 메모리가 설치된 컴퓨터로는 4GB 이상의 프로그램을 실행할 수 없다.
* `가상 메모리 (virtual memory)`는 실행하고자 하는 프로그램을 `일부만 메모리에 적재`하여 실제 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있게 하는 기술이다.
* 크게 `페이징`과 `세그멘테이션`이 있지만, 여기서는 페이징 기법을 다루도록 하겠다.
  * (세그멘테이션은 따로 추가 예정)

### 페이징이란

* 연속 메모리 할당 방식에서 `외부 단편화`가 생긴 근본적인 이유는 `각기 다른 크기`의 프로세스가 메모리에 연속적으로 할당되었기 때문이다.
* 만일 메모리와 프로세스를 일정한 단위로 자르고, 이를 메모리에 `불연속적`으로 할당할 수만 있다면 외부 단편화는 일어나지 않을 것이다.
* 가령 메모리 공간과 프로세스들을 10MB 단위의 일정한 크기로 자르고, 잘린 메모리 조각들에 프로세스 조각들을 불연속적으로 적재할 수 있다면 외부 단편화는 발생하지 않는다.
* 이것이 `페이징 (paging)`이다.
* `페이징`은 프로세스의 `논리 주소 공간`을 `페이지 (page)`라는 일정한 단위로 자르고, 메모리 `물리 주소 공간`을 `프레임 (frame)`이라는 페이지와 동일한 크기의 일정한 단위로 자른 뒤 `페이지를 프레임에 할당하는 가상 메모리 관리 기법`이다.
* 페이징을 사용하는 시스템에서는 페이지 단위로 스왑 아웃/스왑 인이 일어난다. 따라서 `페이지 아웃 (page out)`, `페이지 인 (page in)`이라고 부르기도 한다.

### 페이지 테이블

* 프로세스가 메모리에 불연속적으로 배치되어 있다면 CPU 입장에서 이를 순차적으로 실행할 수 없다. 
* 프로세스를 이루는 페이지가 어느 프레임에 적재되어 있는지 CPU가 모두 알고 있기란 어렵기 때문이다.
* 이를 해결하기 위해 페이징 시스템은 비록 물리 주소에 불연속적으로 배치되더라도 (CPU가 바라보는 주소인) `논리 주소에는 연속적으로 배치`되도록 `페이지 테이블 (page table)`을 이용한다.
* 프로세스마다 각자의 페이지 테이블이 있다. 이를 통해 `페이지 번호`와 `프레임 번호`를 짝지을 수 있다.
* `내부 단편화 (internal fragmentation)`
  * 가령 페이지 크기가 10KB인데, 프로세스의 크기가 108KB인 경우 마지막 페이지는 2KB만큼의 크기가 남는다.
  * 이러한 메모리 낭비를 `내부 단편화`라고 한다.
  * 하지만 그렇다고 하나의 페이지 크기를 너무 작게 설정하면 그만큼 페이지 테이블의 크기도 커지기 때문에 페이지 테이블이 차지하는 공간이 낭비된다. 
  * 그렇기에 적당한 페이지 크기를 조정하는 것이 중요하다.
  * 리눅스를 포함한 일부 OS에서는 기본적으로 설정된 페이지 크기보다 더 큰 크기의 페이지도 일부 허용하며 메모리에 유지하는 경우도 있다. 이를 `대형 페이지 (huge page)`라고 한다.
* 각 프로세스의 `페이지 테이블`들은 `메모리에 적재`되어 있다.
* 그리고 `CPU` 내의 `페이지 테이블 베이스 레지스터 (PTBR: Page Table Base Register)`는 각 프로세스의 페이지 테이블이 적재된 `주소`를 가리키고 있다.
  * 예를 들어 프로세스 A가 실행될 때 `PTBR`은 프로세스 A의 페이지 테이블을 가리키고, CPU는 프로세스 A의 페이지 테이블을 통해 프로세스 A의 페이지가 적재된 프레임을 알 수 있다.
  * 이러한 각 프로세스들의 페이지 테이블 정보들은 각 프로세스의 `PCB`에 기록된다. 그리고 프로세스의 `문맥 교환`이 일어날 때 다른 레지스터와 마찬가지로 함께 변경된다.
    * (문맥 교환 시 PTBR을 비롯한 레지스터의 정보들이 PCB에 기록된다는 뜻인 듯)
* 그런데 페이지 테이블을 메모리에 두게 되면 `메모리 접근 시간`이 2배로 늘어난다는 문제가 생긴다.
* 그래서 이와 같은 문제를 해결하기 위해 CPU 곁에 (일반적으로 `MMU (메모리 관리 장치)` 내에) `TLB (Translation Lookaside Buffer)`라는 페이지 테이블의 `캐시 메모리`를 둔다.
  * TLB는 `참조 지역성`에 근거해 주로 `최근에 사용된 페이지 위주로 가져와 저장`한다.
  * CPU가 발생한 `논리 주소`에 대한 페이지 번호가 TLB에 있을 경우 이를 `TLB 히트`라고 하며 메모리 접근을 한 번만 하면 된다.
  * 반대로 페이지 번호가 TLB에 없을 경우에는 `TLB 미스`라고 하며 메모리 내의 페이지 테이블에 접근할 수밖에 없다.

### 페이징에서의 주소 변환

* 하나의 페이지 혹은 프레임은 여러 주소를 포괄하고 있다.
* 그렇기에 특정 주소에 접근하려면 아래와 같은 2가지 정보가 필요하다.
  * 어떤 페이지 혹은 프레임에 접근하고 싶은지
  * 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있는지
* 그렇기에 페이징 시스템에서는 모든 `논리 주소`가 기본적으로 `페이지 번호 (page number)`와 `변위 (offset)`로 이루어져 있다.
* 가령 CPU가 32비트 주소를 내보냈다면 이 중 N비트는 페이지 번호, 32-N비트는 변위
* 따라서 `논리 주소 <페이지 번호, 변위>`는 `페이지 테이블`을 통해 `물리 주소 <프레임 번호, 변위>`로 변환된다.
  * 변위의 값은 동일하다.

### 페이지 테이블 엔트리

* 페이지 테이블의 각각의 행들을 `페이지 테이블 엔트리 (PTE: Page Table Entry)`라고 한다.
* `PTE`에 담기는 정보에는 `페이지 번호`, `프레임 번호`뿐만 아니라 다른 중요한 정보들도 존재한다. 대표적으로 `유효 비트`, `보호 비트`, `참조 비트`, `수정 비트`이다.

#### 유효 비트

* `유효 비트 (valid bit)`는 현재 해당 페이지에 `접근 가능한지 여부`를 알려준다.

* 일반적으로 프로세스를 이루는 모든 페이지가 메모리에 있지는 않다. 일부 페이지는 보조기억장치 (`스왑 영역`)에 있는 경우가 많다.

* 페이지가 `메모리에 적재되어 있다면 유효 비트가 1`, `메모리에 적재되어 있지 않다면 유효 비트가 0`이다.

* 만일 CPU가 `유효 비트가 0`인 `메모리에 적재되어 있지 않은` 페이지로 접근하려고 하면 `페이지 폴트 (page fault)`라는 `예외 (exception)`이 발생하게 된다.

* CPU가 `페이지 폴트`를 처리하는 과정은 하드웨어 인터럽트를 처리하는 과정과 유사하다.

  > 1. CPU는 기존의 작업 내역을 백업한다.
  > 2. `페이지 폴트 처리 루틴`을 실행한다.
  > 3. `페이지 폴트 처리 루틴`은 원하는 페이지를 메모리로 가져온 뒤 `유효 비트를 1로 변경`해준다.
  > 4. 페이지 폴트를 처리했다면 이제 CPU는 해당 페이지에 접근할 수 있다.
  >

#### 보호 비트

* `보호 비트 (protection bit)`는 `페이지 보호 기능`을 위해 존재하는 비트이다.
* 보호 비트를 통해 해당 페이지가 `읽고 쓰기가 모두 가능`한 페이지인지, 혹은 `읽기만 가능`한 페이지인지를 나타낼 수 있다.
* 가령 `읽기만 가능한 경우 보호 비트가 0`, `읽고 쓰기가 모두 가능한 경우 보호 비트가 1`이다.
* 예를 들어 `코드 영역`과 같은 읽기 전용 영역에 쓰기를 시도하면 OS가 이를 막아준다.
*  `읽기 (Read)를 나타내는 r`, `쓰기 (Write)를 나타내는 w`, `실행 (eXecute)를 나타내는 x` 3개의 비트조합을 이용해서 권한을 나타낼 수 있다.
  * 예를 들어 보호 비트가 111인 페이지인 경우 읽기, 쓰기 ,실행이 모두 가능하다.  

#### 참조 비트

* `참조 비트 (reference bit)`는 `CPU가 이 페이지에 접근한 적이 있는지 여부`를 나타낸다. 
* `적재 이후 CPU가 읽거나 쓴 페이지는 참조 비트가 1`로 세팅되고, `적재 이후 한 번도 읽거나 쓴 적이 없는 페이지는 0`으로 유지된다.

#### 수정 비트

* `수정 비트 (modified bit)`는 해당 페이지에 `데이터를 쓴 적이 있는지 없는지 수정 여부`를 알려준다. `더티 비트 (dirty bit)`라고도 부른다.
* 이 비트가 `1이면 변경된 적이 있는 페이지`, `0이면 변경된 적이 없는 페이지 (한 번도 접근한 적 없거나 읽기만 한 페이지)`임을 나타낸다.
* 수정 비트는 페이지가 `메모리에서 사라질 때 보조기억장치에 쓰기 작업을 해야 하는지, 할 필요가 없는지`를 판단하기 위해 존재한다.
* `수정 비트가 0`인 페이지가 `스왑 아웃`될 경우 아무런 추가 작업 없이 새로 적재된 페이지로 덮어쓰기만 하면 된다.

### 페이징의 이점 - 쓰기 시 복사

* `외부 단편화` 문제를 해결한다는 점 이외에도 페이징이 제공하는 이점은 다양하다.
* 대표적인 것이 프로세스 간에 `페이지를 공유`할 수 있다는 점이다.
* 프로세스 간 페이지를 공유하는 사례로는 `공유 라이브러리` 등 다양하지만, 대표적인 예시로 `쓰기 시 복사 (copy on write)`가 있다.
* 유닉스나 리눅스 같은 OS에서 `fork` 시스템 호출을 하면 부모 프로세스의 복사본이 자식 프로세스로서 만들어진다.
* `쓰기 시 복사`에서는 부모 프로세스와 동일한 자식 프로세스가 생성되면 자식 프로세스로 하여금 부모 프로세스와 동일한 프레임을 가리키도록 한다.
* 이로써 굳이 부모 프로세스의 메모리 공간을 복사하지 않고도 동일한 코드 및 데이터 영역을 가리킬 수 있다.
* 만일 부모 프로세스와 자식 프로세스가 메모리에 어떠한 데이터도 쓰지 않고 그저 읽기 작업만 이어 나간다면 이 상태가 지속된다.
* 그러다 둘 중 하나가 페이지에 쓰기 작업을 하면 그 순간 해당 페이지가 별도의 공간으로 복제된다. 각 프로세스는 자신의 고유한 페이지가 할당된 프레임을 가리키게 된다. 이것이 `쓰기 시 복사`이다.
* 이러한 쓰기 시 복사를 통해 `프로세스 생성 시간을 줄이는 것`은 물론 `메모리 공간 절약`도 가능하다.

### 계층적 프레임

* 페이지 테이블의 크기는 생각보다 작지 않다.

* 프로세스의 크기가 커지면 자연히 프로세스 테이블의 크기도 커지기 때문에 프로세스를 이루는 모든 `페이지 테이블 엔트리`를 메모리에 두는 것은 큰 메모리 낭비이다.

* 이에 프로세스를 이루는 모든 PTE를 항상 메모리에 유지하지 않을 수 있는 방법이 등장했는데, 이것이 `계층적 페이징 (hierarchical paging)`이다.

* 계층적 페이징은 `페이지 테이블을 페이징`하여 `여러 단계의 페이지를 두는 방식`이다.

* `다단계 페이지 테이블 (multilevel page table)` 기법이라고도 부른다.

* 프로세스의 페이지 테이블을 여러 개의 페이지로 자르고, 바깥쪽에 페이지 테이블을 하나 더 두어 잘린 페이지 테이블의 페이지들을 가리키게 하는 방식이다.

* 계층적 페이징을 이용하는 환경에서의 `논리 주소`는 다음과 같은 형태로 만들어진다.

  * `바깥 페이지 번호` - `안쪽 페이지 번호` - `변위`

  * 바깥 페이지 번호에 해당하는 항목은 CPU와 근접한 곳에 위치한(바깥에 위치한) 페이지 테이블 엔트리를 가리키고,

  * 안쪽 페이지 번호는 첫 번째 페이지 테이블 바깥에 위치한 두 번째 페이지 테이블, 즉 페이지 테이블의 페이지 번호를 가리킨다.

    > 1. 바깥 페이지 번호를 통해 페이지 테이블의 페이지를 찾기
    > 2. 페이지 테이블의 페이지를 통해 프레임 번호를 찾고 변위를 더함으로써 물리 주소 얻기

  * 페이지 테이블의 게층은 3개, 4개, 그 이상의 계층으로도 구성될 수 있다.

  * 다만 페이지 테이블의 계층이 늘어날수록 `페이지 폴트`가 발생했을 경우 `메모리 참조 횟수`가 많아지므로 계층이 많다고 해서 반드시 좋다고 볼 수는 없다.

## 14-3 페이지 교체와 프레임 할당

* 가상 메모리를 통해 작은 물리 메모리보다 큰 프로세스도 실행할 수 있다.
* 그럼에도 불구하고, 물리 메모리의 크기는 한정되어 있다.
* OS는 프로세스들이 한정된 메모리를 효율적으로 이용할 수 있어야 하고, 프로세스들에 적절한 수의 프레임을 할당하여 페이지를 할당할 수 있게 해야 한다.
* 이번 절에서는 `요구 페이징`의 개념과 `페이지 교체 알고리즘`, 그리고 `프레임 할당`에 대해 알아보자.

### 요구 페이징

* 프로세스를 메모리에 적재할 때 처음부터 모든 메모리를 적재하지 않고 `필요한 페이지만을 메모리에 적재하는 기법`을 `요구 페이징 (demand paging)`이라고 한다.

* 요구 페이징의 기본적인 양상은 다음과 같다.

  > 1. CPU가 특정 페이지에 접근하는 명령어를 실행한다.
  > 2. 해당 페이지가 현재 메모리에 있을 경우 (유효 비트가 1일 경우) CPU는 페이지가 적재된 프레임에 접근한다.
  > 3. 해당 페이지가 현재 메모리에 없을 경우 (유효 비트가 0일 경우) 페이지 폴트가 발생한다.
  > 4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고 유효 비트를 1로 설정한다.
  > 5. 다시 1번을 수행한다.
  >
* 아무런 페이지도 메모리에 적재하지 않은 채 무작정 실행부터 할 수도 있다.

  * 이 경우 프로세스의 첫 명령어를 실행하는 순간부터 `페이지 폴트`가 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트 발생 빈도가 떨어진다.
  * 이를 `순수 요구 페이징 (pure demand paging)` 기법이라고 한다.

* 요구 페이징 시스템이 안정적으로 작동하려면 `페이지 교체`와 `프레임 할당`이 적절히 이뤄져야 한다.

### 페이지 교체 알고리즘

* 일반적으로 `페이지 폴트`를 가장 적게 일으키는 알고리즘을 좋은 알고리즘으로 평가한다.
* 가령 한 알고리즘을 통해 고른 페이지를 `스왑 아웃`시켰을 때 페이지 폴트가 자주 발생하면 이는 좋은 알고리즘이 아니다.
* 페이지 교체 알고리즘을 제대로 이해하려면 `페이지 폴트 횟수`를 알 수 있어야 한다.
* 그리고 페이지 폴트 횟수는 `페이지 참조열 (page reference string)`을 통해 알 수 있다.
  * 가령 CPU가 다음과 같은 수서로 페이지에 접근했다고 가정해보자.
    * 2 2 2 3 5 5 5 3 7
  * 여기서 연속된 페이지를 생략한 페이지열이 페이지 참조열이다.
    * 2 3 5 3 7

#### FIFO 페이지 교체 알고리즘

* `FIFO 페이지 교체 알고리즘`은 적재된 페이지 순서대로 교체하는 알고리즘이다.

* 가령 페이지 참조열이 2 3 1 3 5 2 3 4 2 3 일 때, 프레임이 3개일 경우

  * 최초에 페이지를 적재할 때 페이지 폴트가 3번 발생하고,
  * 이후 페이지가 페이지가 교체되며 페이지 폴트가 4번 발생한다.

* FIFO 페이지 교체 알고리즘은 자칫 자주 참조되는 페이지가 먼저 적재되었다는 이유만으로 내쫓길 수 있다는 문제가 있었다.

* `2차 기회 페이지 교체 알고리즘`은 이러한 부작용을 어느 정도 개선한 FIFO 페이지 교체 알고리즘의 변형이다.

  * 페이지 교체 시 가장 오래 머물렀던 페이지의 참조 비트가 1인 경우, 참조 비트를 0으로 만들고 적재 시간을 현재 시간으로 설정한다.

  * 그 후 만일 다음으로 오랫동안 머물렀던 페이지의 참조 비트가 0인 경우, 해당 페이지를 내보내고 새로운 페이지를 적재한다.

#### 최적 페이지 교체 알고리즘

* `최적 페이지 교체 알고리즘`은 `CPU에 의해 참조되는 횟수`를 고려하는 페이지 교체 알고리즘이다.
* 다만 프로세스가 앞으로 사용하지 않을 페이지를 `미리 알아야 한다`는 점에서 `구현이 불가능`하다.
* 따라서 실제 구현 목적보다는 다른 알고리즘과의 `비교 연구` 목적으로 주로 이용된다.

#### LRU 페이지 교체 알고리즘

* 가장 오랫동안 사용되지 `않을` 페이지를 교체하는 알고리즘을 구현하기 어렵다면, `가장 오랫동안 사용되지 않은` 페이지를 교체하는 알고리즘은 구현이 가능하다. 이 알고리즘이 바로 `LRU 페이지 교체 알고리즘`이다.

### 스래싱과 프레임 할당

* 페이지 교체 알고리즘의 성능과는 별개로, 프로세스가 `사용할 수 있는 프레임 수`가 적어도 페이지 폴트가 자주 발생한다. (사실 이것이 더 근본적인 이유라고 볼 수 있다.)
* 프레임이 부족하다면 CPU는 `페이지 폴트`가 자주 발생할 수밖에 없고, CPU의 이용률도 떨어지게 된다.
* 이처럼 `프로세스가 실제 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저해되는 문제`를 `스래싱 (thrashing)`이라고 한다. 즉, `지나치가 빈번한 페이지 교체로 인해 CPU 이용률이 낮아지는 문제`를 뜻한다.
* `메모리에서 동시에 실행되는 프로세스의 수`를 `멀티프로그래밍의 정도 (degree or multiprogramming)`라고 한다.
* 멀티 프로그래밍의 정도를 늘린다고 해서 CPU 이용률이 그에 비례해서 증가하는 것만은 아니다. 일정 정도를 넘어서면 각 프로세스들이 사용할 수 있는 프레임 수가 적어지기 때문에 `페이지 폴트`가 지나치가 빈번히 발생하고, 따라서 CPU 이용률도 떨어지게 된다.
* `스래싱`이 발생하는 근본적인 원인은 `각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않았기 때문`이다.
* 그렇기에 OS는 각 프로세스들이 무리 없이 실행하기 위한 최소한의 프레임 수를 파악하고 프로세스들에 적절한 수만큼 프레임을 할당할 수 있어야 한다.
* `정적 할당 방식`
  * 먼저 가장 단순한 형태의 프레임 할당 방식부터 생각해보자.
    * 가령 3개의 프로세스에 300개의 프레임을 할당할 수 있을 때, 각 프로세스의 100개의 프레임을 할당하는 방식을 `균등 할당 (equal allocation)`이라고 한다.
    * 하지만 프로세스 크기를 고려하지 않고 모두 동일한 프레임을 할당하는 것은 비효율적이다. 따라서 `프로세스의 크기`에 따라 프레임을 할당하는 방식을 `비례 할당 (proportional allocation)`이라고 한다.
    * 위 2 방식은 프로세스의 실행 과정을 고려하지 않고 단순히 프로세스의 크기와 물리 메모리의 크기만을 고려한 방식이라는 점에서 `정적 할당 방식`이라고도 한다.

  * 하지만 비례 할당 방식도 완벽하진 않다. 프로세스의 크기가 클지라도 막상 실행해보니 많은 프레임을 필요로 하지 않는 경우도 있고, 그 반대도 마찬가지이다. 즉, 하나의 프로세스가 실제로 얼마나 많은 프레임이 필요할지는 결국 실행해 봐야 아는 경우가 많다.

* `동적 할당 방식`
  * 프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식에는 크게 `작업 집합 모델 (working set model)`을 사용하는 방식과 `페이지 폴트 빈도 (PPF: Page-Fault Frequency)`를 사용하는 방식이 있다.
  * `작업 집합  모델`
    * `스래싱`이 발생하는 이유는 빈번한 페이지 교체 때문이다.
    * 그렇기에 작업 집합 모델 기반 프레임 할당 방식은 `프로세스가 일정 기간 동안 참조한 페이지 집합`을 기억하여 빈번한 페이지 교체를 방지한다.
    * CPU가 메모리를 참조할 때에는 `참조 지역성`의 원리에 의거해 주로 비슷한 구역을 집중적으로 참조한다.
    * 가령 CPU가 어떤 프로세스를 실행하는 동안 3초에 20개의 페이지를 집중적으로 참조했다면 OS는 그 프로세스를 위해 그 순간만큼은 최소 20개의 프레임을 할당하면 된다.
    * 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 `작업 집합 (working set)`이라고 한다.
    * CPU가 과거

